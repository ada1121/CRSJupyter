{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyxlsb as px\n",
    "import linecache\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime \n",
    "\n",
    "\n",
    "import qgrid\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing\n",
    "## 1.1 Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAP VA05 File ---\n",
    "#File path\n",
    "va_file_dir = r'C:\\Users\\the7490\\MDLZ\\Central Analytics Team CAT - Projects\\Beta Quadrant\\KUNLUN\\01.Raw Data\\VA05_CSV'\n",
    "\n",
    "#get file name list\n",
    "va_file_list = os.listdir(va_file_dir)\n",
    "new_list = []\n",
    "\n",
    "\n",
    "for file in va_file_list:\n",
    "    #construct file path\n",
    "    file_path = os.path.join(va_file_dir,file)\n",
    "    \n",
    "    df = pd.read_csv(file_path , encoding = 'utf-8',thousands= r',')\n",
    "    \n",
    "    df['Doc. Date'] = pd.to_datetime(df['Doc. Date'])\n",
    "\n",
    "    df = df.rename(columns=lambda x: x.strip())\n",
    "    \n",
    "    new_list.append(df)\n",
    "    # print(file)\n",
    "    \n",
    "#Combine data\n",
    "va = pd.concat(new_list)\n",
    "\n",
    "# --- CRS data ---\n",
    "file_dir = r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\crs_order'\n",
    "file_list = os.listdir(file_dir)\n",
    "new_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(file_dir,file)\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    new_list.append(dataframe)\n",
    "    \n",
    "#Combine data\n",
    "crs = pd.concat(new_list)\n",
    "\n",
    "# --- Boundary data ---\n",
    "file_dir = r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\min_max_intentory_date'\n",
    "\n",
    "\n",
    "file_list = os.listdir(file_dir)\n",
    "new_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(file_dir,file)\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    new_list.append(dataframe)\n",
    "\n",
    "    \n",
    "boundary = pd.concat(new_list)\n",
    "\n",
    "# SKU mapping - Master\n",
    "sku_mapping = pd.read_excel(r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\SKU Category Mapping List V2.xlsx', engine = \"xlrd\")\n",
    "sku_mapping = sku_mapping[['sku_code','Category']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qual_quant_features(data):\n",
    "    dtypes = list(map(lambda x:str(x),list(data.dtypes)))\n",
    "    qualitative = []\n",
    "    quantitative = []\n",
    "    for i in range(len(dtypes)):\n",
    "        if dtypes[i] == 'object':\n",
    "            qualitative.append(data.columns[i])\n",
    "        else:\n",
    "            quantitative.append(data.columns[i])\n",
    "    return qualitative,quantitative\n",
    "\n",
    "qualitative,quantitative = qual_quant_features(va)\n",
    "\n",
    "# Create a function to show result\n",
    "def result_show(path):\n",
    "    return qgrid.show_grid(path,show_toolbar = True)\n",
    "\n",
    "# new\n",
    "def trim(df):\n",
    "    df_obj = df.select_dtypes(['object'])\n",
    "    df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip()) #trim\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Clean Data - SAP VA05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out wanted columns \n",
    "va_df = va[['Rj','PO Number','Sold-To Pt','Name 1','Material','Description','Plnt','Order Qty','ConfirmQty','Doc. Date','Cust.price','Net price','SaTy']]\n",
    "va_df = va_df[va_df['Order Qty']>0]\n",
    "va_df[['Sold-To Pt','Material']] = va_df[['Sold-To Pt','Material']].astype(float).astype(int).astype(str)\n",
    "\n",
    "\n",
    "# Saty == ZOR  and PO number start with VZO for CRS customer\n",
    "va_df =  va_df[va_df['SaTy']=='ZOR']\n",
    "va_df = va_df[va_df['PO Number'].str.contains(r'VZO*')]\n",
    "\n",
    "# Replace null with 0 for Rj\n",
    "va_df['Rj'] = va_df['Rj'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Remove 61 code\n",
    "va_df = va_df[va_df['Rj']!= 61]\n",
    "\n",
    "# Set Rj=10 if order_qty > confrimQty and Rj is null\n",
    "# va_df['Rj'] = va_df[['Order Qty','ConfirmQty','Rj']].apply(lambda x: 10 if x['Rj']== 0 and x['Order Qty']> x['ConfirmQty'] else x['Rj'], axis =1)\n",
    "\n",
    "# Gourp by Customer, Material, Date to map CRS data and count \n",
    "va_df_grouped = va_df[['Order Qty','ConfirmQty','Sold-To Pt','Material','Doc. Date','Rj']].groupby([\"Sold-To Pt\",'Material','Doc. Date']).agg({'Order Qty':'sum','ConfirmQty':'sum','Rj':'count'}).reset_index()\n",
    "va_df_grouped.rename(columns ={'Rj':'count'}, inplace = True)\n",
    "\n",
    "\n",
    "# Get Customer and SKU Info\n",
    "va_cus = va_df[[\"Sold-To Pt\",'Name 1','Plnt']].drop_duplicates(subset=['Sold-To Pt'],keep='first',inplace=False)\n",
    "va_df_grouped_cus = pd.merge(va_df_grouped, va_cus, on = 'Sold-To Pt',how = 'left')\n",
    "\n",
    "va_sku = va_df[[\"Material\",'Description','Net price']].drop_duplicates(subset=['Material'],keep='first',inplace=False)\n",
    "df_va = pd.merge(va_df_grouped_cus, va_sku, on = 'Material',how = 'left')\n",
    "\n",
    "# df_va =  pd.merge(df_va, date[['Date','year','week']], left_on = 'Doc. Date',right_on = 'Date',how = 'left') \n",
    "df_va['year'] = df_va['Doc. Date'].dt.year.astype(int)\n",
    "df_va['week'] = df_va['Doc. Date'].apply(lambda x: x.strftime(\"%W\")).astype(int)      \n",
    "df_va['ds'] = df_va['Doc. Date'].apply(lambda x: x.strftime(\"%Y%m%d\")).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34520211.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_va['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Clean data - CRS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \\N with null\n",
    "crs = crs.replace({r'\\N': None})\n",
    "\n",
    "# Set data type\n",
    "crs['calc_date'] = pd.to_datetime(crs['calc_date'])\n",
    "\n",
    "crs[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5']] = crs[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5']].astype(float)\n",
    "crs[['sold_to_pt','material','ds']] = crs[['sold_to_pt','material','ds']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = crs.drop(columns=['year','week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Clean data - boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary.drop_duplicates(subset=['CategoryName','ReceiverCode'], keep='first',inplace=True)\n",
    "boundary = boundary.drop(columns=['CategoryCode','HotFlag','ReceiverName', 'InsertTime'])\n",
    "boundary[['ReceiverCode']] = boundary[['ReceiverCode']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.59 GiB for an array with shape (11, 19418782) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-01f168588350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# merge crs and va\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mva_crs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_va\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sold-To Pt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Material'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sold_to_pt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'material'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# merge sku mapping to get category\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mva_crs_sku\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva_crs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msku_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'material'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sku_code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mright_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mleft_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_labels_or_levels\u001b[1;34m(self, keys, axis)\u001b[0m\n\u001b[0;32m   1856\u001b[0m             \u001b[1;31m# Handle dropping columns labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels_to_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1858\u001b[1;33m                 \u001b[0mdropped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_to_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1859\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m             \u001b[1;31m# Handle dropping column levels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4913\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4914\u001b[0m         )\n\u001b[0;32m   4915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4185\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4186\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4188\u001b[0m         \u001b[1;31m# Case for non-unique axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4771\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4772\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4774\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4817\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4818\u001b[0m         return self._reindex_axes(\n\u001b[1;32m-> 4819\u001b[1;33m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4820\u001b[0m         ).__finalize__(self, method=\"reindex\")\n\u001b[0;32m   4821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4591\u001b[0m             frame = frame._reindex_columns(\n\u001b[1;32m-> 4592\u001b[1;33m                 \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4593\u001b[0m             )\n\u001b[0;32m   4594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_columns\u001b[1;34m(self, new_columns, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4638\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4639\u001b[0m             \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4640\u001b[1;33m             \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4641\u001b[0m         )\n\u001b[0;32m   4642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   4887\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4888\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4889\u001b[1;33m                 \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4890\u001b[0m             )\n\u001b[0;32m   4891\u001b[0m             \u001b[1;31m# If we've made a copy once, no need to make another one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[1;32m--> 677\u001b[1;33m                 \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monly_slice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0monly_slice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m             )\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[0;32m    817\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m                         \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m         new_values = algos.take_nd(\n\u001b[1;32m-> 1145\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m         )\n\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\array_algos\\take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\array_algos\\take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.59 GiB for an array with shape (11, 19418782) and data type float64"
     ]
    }
   ],
   "source": [
    "# merge crs and va\n",
    "va_crs = pd.merge(df_va, crs,left_on=['Sold-To Pt','Material','ds'],right_on=['sold_to_pt','material','ds'], how='left')\n",
    "\n",
    "# merge sku mapping to get category \n",
    "va_crs_sku = pd.merge(va_crs, sku_mapping,left_on=['material'],right_on=['sku_code'],how='left')\n",
    "\n",
    "#  merge boundary\n",
    "va_crs_sku_bdy = pd.merge(va_crs_sku, boundary,left_on=['sold_to_pt','Category'],right_on=['ReceiverCode','CategoryName'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_crs_sku_bdy['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = trim(va_crs_sku_bdy)\n",
    "\n",
    "# Fill NA min as 14 and max as 28\n",
    "df_prep['MinDays'] = df_prep['MinDays'].replace(np.nan, 14).astype(int)\n",
    "df_prep['MaxDays'] = df_prep['MaxDays'].replace(np.nan, 28).astype(int)\n",
    "\n",
    "# keep records of ordered date only\n",
    "df_prep = df_prep[df_prep['order_qty']>0]\n",
    "\n",
    "# remove avg_sale < 0\n",
    "df_prep = df_prep[df_prep['avg_sales_box_day']>0]\n",
    "\n",
    "# remove duplicated columns\n",
    "df_prep = df_prep.drop(columns=['Sold-To Pt','Material','sku_code','ReceiverCode','calc_date'])\n",
    "\n",
    "# set data type and  replace fill na with 0\n",
    "df_prep[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5']] = df_prep[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5']].fillna(0).astype(float)\n",
    "\n",
    "df_prep['sale_month'] = (df_prep['sale_box_week1']+ df_prep['sale_box_week2']+ df_prep['sale_box_week3']+ df_prep['sale_box_week4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27073617.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50beaec5cfb4849b420aee24120ea2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_show(va_crs_sku_bdy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88645, 35)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_crs_sku_bdy[va_crs_sku_bdy['material'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180667, 35)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_crs_sku_bdy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180667, 13)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_crs_sku_bdy['Material'] = va_crs_sku_bdy['Material'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 244090,  244336,  244338,  244340,  244344,  357405,  357407,\n",
       "       4009396, 4010501, 4010502, 4010503, 4010504, 4010995, 4015343,\n",
       "       4015380, 4015382, 4025396, 4038469, 4040512, 4040514, 4040516,\n",
       "       4040518, 4042308, 4042314, 4042327, 4042334, 4043243, 4043248,\n",
       "       4043263, 4043987, 4043988, 4043989, 4043990, 4043997, 4043998,\n",
       "       4043999, 4044000, 4044001, 4044002, 4044003, 4044005, 4044006,\n",
       "       4044007, 4044009, 4044011, 4044012, 4044015, 4044016, 4044017,\n",
       "       4044019, 4044020, 4044025, 4048994, 4054458, 4054459, 4061001,\n",
       "       4061003, 4061347, 4061348, 4061349, 4061491, 4061492, 4061812,\n",
       "       4074918, 4074920, 4074922, 4074924, 4077890, 4077896, 4077899,\n",
       "       4079795, 4080617, 4080620, 4080624, 4081339, 4081342, 4081344,\n",
       "       4081351, 4081352, 4081353, 4081355, 4081445, 4081447, 4081450,\n",
       "       4081452, 4082386, 4082481, 4084413, 4084414, 4252074, 4252265,\n",
       "       4256679, 4257609, 4257684, 4257685, 4257803, 4257804, 4257806,\n",
       "       4257847, 4258683, 4258685, 4258687, 4258688, 4258800, 4258803,\n",
       "       4258804, 4259561, 4259562, 4259585, 4259719, 4259720, 4259721,\n",
       "       4259723, 4260050, 4260051, 4260375, 4260412, 4260475, 4260476,\n",
       "       4262056, 4262057, 4262058, 4262069, 4262072, 4262073, 4262074,\n",
       "       4262076, 4262077, 4262078, 4262079, 4262080, 4262081, 4262090,\n",
       "       4262091, 4263045, 4264455, 4266395, 4266579, 4266581, 4266586,\n",
       "       4266589, 4267218, 4267851, 4267852, 4268309, 4268310, 4268311,\n",
       "       4268337, 4269101, 4269116, 4269117, 4269118, 4269119, 4269172,\n",
       "       4269173, 4270167, 4270168, 4270278, 4270285, 4270317, 4272720,\n",
       "       4273104, 4273105, 4273216, 4273217, 4273218, 4273310, 4273324,\n",
       "       4273826, 4273827, 4273828, 4274870, 4275482, 4276028, 4276461,\n",
       "        610123,  610248,  610250,  610252,  610479,  646833,  647523,\n",
       "        647524,  658352,  658355,  658359,  681470,  681480,  686119,\n",
       "        756921,  763982,  763986,  847459,  847473,  923742,  923756,\n",
       "        924754,  924757,  968470,  969435,  969439,  969441,  969444,\n",
       "        969585,  974350,  974352,  974356,  113944,  114264,  114266,\n",
       "        244086,  244156,  244158,  244308,  244310,  323548, 4014727,\n",
       "       4025096, 4025101, 4025132, 4025134, 4043034, 4043036, 4043994,\n",
       "       4043995, 4043996, 4044004, 4044008, 4044026, 4044027, 4044029,\n",
       "       4044030, 4045384, 4045385, 4045387, 4053375, 4054460, 4054461,\n",
       "       4077893, 4077902, 4079792, 4080864, 4080966, 4081312, 4081320,\n",
       "       4081330, 4081346, 4082478, 4082479, 4082480, 4084415, 4084765,\n",
       "       4252301, 4252573, 4255041, 4257481, 4258807, 4260473, 4260474,\n",
       "       4260705, 4261382, 4261383, 4261458, 4261459, 4261460, 4264507,\n",
       "       4267801, 4267828, 4270169, 4270170, 4273103, 4276030,  609551,\n",
       "        609552,  610386,  611237,  628412,  628419,  646814,  646815,\n",
       "        646825,  646830,  646831,  646832,  646836,  648728,  648729,\n",
       "        648730,  648733,  678649,  678654,  753770,  753774,  763993,\n",
       "        763996,  788426,  788761,  788763,  924750,  924753,  970709,\n",
       "        970710,  972001,  972003,  972004,  972335,  972336,  972337,\n",
       "        972342,  972344,  972346, 4000037, 4009402, 4043991, 4043992,\n",
       "       4043993, 4061216, 4074584, 4079773, 4079786, 4081347, 4081348,\n",
       "       4082389, 4257802, 4260246, 4267537,  850980,  923740,  974345,\n",
       "        974347,  974349, 4045227, 4045228, 4077040, 4077043, 4079789,\n",
       "       4087708, 4087710, 4256937, 4265763, 4267959, 4267960, 4273403,\n",
       "        628423,  113714,  113715,  113721,  113722,  113941,  113942,\n",
       "        113943,  113945,  113953,  113954,  113955,  113958,  114265,\n",
       "        114267, 4267957, 4267958, 4269120, 4269121, 4274140, 4274267,\n",
       "        609550,  609565,  646835,  646855,  646859,  662491, 4024638,\n",
       "       4024640, 4265836, 4266590, 4266592, 4274872, 4276460, 4079777,\n",
       "       4260410, 4273527,  923757, 4024639, 4062957, 4062958, 4076636,\n",
       "        323545, 4038930, 4253180,  646837,  924758,  924759, 4273212,\n",
       "       4273213, 4273214, 4275481, 4261685, 4044034, 4259789, 4259793,\n",
       "        323550, 4261684,  675417,  675420,  969442,  610242,  610243,\n",
       "       4083398, 4274393, 4274394, 4274395, 4274397, 4274399, 4274400,\n",
       "       4274822, 4274823, 4274824, 4274864, 4274865, 4274867,  662302,\n",
       "        923741,  847475, 4083397, 4267538, 4274396, 4274419,  628414,\n",
       "       4081340, 4252775, 4257225, 4256009, 4273326, 4256209, 4053717,\n",
       "       4044035, 4267708, 4259567, 4259568, 4259569, 4274871,  923753,\n",
       "        608663, 4084764, 4263841, 4058507, 4075400,  859061,  647526,\n",
       "        756923,  628415, 4053720, 4053719, 4069680, 4261242, 4261243,\n",
       "       4261244, 4261940])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_crs_sku_bdy['Material'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply shortage tag via CRS data including reason code 61 (customer real need)\n",
    "# SAP data starts from 2020\n",
    "crs['year'] = crs['calc_date'].dt.year.astype(int)\n",
    "crs['week'] = crs['calc_date'].apply(lambda x: x.strftime(\"%W\")).astype(int)  \n",
    "crs_incl_61 = crs\n",
    "\n",
    "crs_incl_61 = crs_incl_61[['order_qty','pgi_qty','year','week','material']].groupby(['year','week','material']).sum().reset_index()\n",
    "\n",
    "# CFR < 93% → shorage\n",
    "crs_incl_61['Shortage_incl_61'] = crs_incl_61[['order_qty','pgi_qty']].apply(lambda x: 'shortage' if x['pgi_qty']/x['order_qty'] < 0.93 else 'normal', axis = 1)\n",
    "\n",
    "# merge\n",
    "df_prep = pd.merge(df_prep, crs_incl_61[['year','week','material','Shortage_incl_61']], on = ['year','week','material'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define order and pgi type\n",
    "def assign_order_type(df):\n",
    "    order = df['Order Qty']\n",
    "    inv = df['avail_inventory_box']\n",
    "    # trs = df['intrans_inventory_box']\n",
    "    mx = df['MaxDays']\n",
    "    mi = df['MinDays']\n",
    "    avg = df['avg_sales_box_day']\n",
    "    \n",
    "    if order+inv > mx*avg :\n",
    "        return 'over'\n",
    "    elif order+inv < mi*avg :\n",
    "        return 'under'\n",
    "    else: # order+inv between(mi*avg, mx*avg)\n",
    "        return 'normal'\n",
    "    \n",
    "def assign_pgi_type(df):\n",
    "    pgi = df['ConfirmQty']\n",
    "    inv = df['avail_inventory_box']\n",
    "    mx = df['MaxDays']\n",
    "    mi = df['MinDays']\n",
    "    avg = df['avg_sales_box_day']\n",
    "    \n",
    "    if pgi+inv > mx*avg :\n",
    "        return 'exceeded'\n",
    "    elif pgi+inv < mi*avg :\n",
    "        return 'lacking'\n",
    "    else: # pgi+inv between(mi*avg, mx*avg)\n",
    "        return 'normal'\n",
    "    \n",
    "df_prep['order_type'] = df_prep.apply(assign_order_type,axis=1)\n",
    "df_prep['pgi_type'] = df_prep.apply(assign_pgi_type,axis=1)\n",
    "\n",
    "df_prep.rename(columns = {'Shortage_incl_61': 'shortage'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Allocation \n",
    "## 2.1 Calculate Gap and exceed amount for shortage records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3106537"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exceed amount: take both max boundary and following month sale into consideration \n",
    "    # exceed box = pgi - avail_inventory - max( MaxBoundary* avg_sales, sales_month)\n",
    "exceed_pgi_box = []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,sale,avg in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['sale_month'],df['avg_sales_box_day']):\n",
    "    if stg == 'shortage' and ot == 'over' and pt == 'exceeded':\n",
    "        if inv > mx*avg:  # Case a:  consider max boundary\n",
    "            ex_a = pgi #exceed = pgi \n",
    "        elif inv+pgi<=mx*avg:\n",
    "            ex_a = 0 # no exceed pgi\n",
    "        else: \n",
    "            ex_a = pgi + inv - mx*avg\n",
    "        if pgi+inv > sale: # Case b: consider sales in following month\n",
    "            ex_b = pgi+inv-sale # not sell in a month\n",
    "        elif pgi+inv <= sale: #  pgi+inv <= sale sell in a month\n",
    "            ex_b = 0\n",
    "        else:\n",
    "            ex_b = None\n",
    "        exceed_pgi_box.append(min(ex_a,ex_b))\n",
    "    else:\n",
    "        exceed_pgi_box.append(None)\n",
    "\n",
    "        \n",
    "df['exceed_pgi_box'] = exceed_pgi_box \n",
    "df['exceed_pgi_box'].sum().astype(int) #3,106,537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443076"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenario 1： \n",
    "    # normal/under ordering GAP = order - pgi - avail_inventory - transit\n",
    "    # over orderging and !exceeded pgi type GAP = max boundary * avg_sales, sale_month - pgi - avail_inventory - transit\n",
    "gap_box_s1 = []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,mi,avg in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['MinDays'],df['avg_sales_box_day']):\n",
    "    if stg == 'shortage':\n",
    "        if ot != 'over':\n",
    "            gap_box_s1.append(max(order - pgi - inv,0))\n",
    "        elif ot == 'over' and pt !='exceeded': \n",
    "            gap_box_s1.append(max(mx*avg - pgi - inv,0))\n",
    "        else:        \n",
    "            gap_box_s1.append(None)\n",
    "    else:\n",
    "        gap_box_s1.append(None)\n",
    "        \n",
    "df['gap_box_s1'] = gap_box_s1\n",
    "df['gap_box_s1'].sum().astype(int) # 443,076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenario 2： \n",
    "    # normal GAP = min*avg - pgi - avail_inventory\n",
    "    # under ordering GAP = order - pgi - avail_inventory\n",
    "    # over ordering and !exceeded pgi GAP = min*avg - pgi - avail_inventory\n",
    "gap_box_s2= []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,mi,avg in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['MinDays'],df['avg_sales_box_day']):\n",
    "    if stg == 'shortage' :\n",
    "        if ot == 'normal':\n",
    "            gap_box_s2.append(max(mi*avg - pgi - inv,0))\n",
    "        elif ot == 'under': \n",
    "            gap_box_s2.append(max(order-pgi-inv,0))\n",
    "        elif ot == 'over' and pt !='exceeded': \n",
    "            gap_box_s2.append(max(mi*avg - pgi - inv,0))\n",
    "        else:\n",
    "            gap_box_s2.append(None)\n",
    "    else:\n",
    "        gap_box_s2.append(None)\n",
    "\n",
    "df['gap_box_s2'] = gap_box_s2\n",
    "df['gap_box_s2'].sum().astype(int) # 278,806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65147"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenario 3：OWA/avail_inventory  ==0  \n",
    "    # normal GAP = min*avg - pgi - avail_inventory\n",
    "    # under ordering GAP = order - pgi - avail_inventory\n",
    "    # over ordering and normal pgi GAP = min*avg - pgi - avail_inventory\n",
    "gap_box_s3= []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,mi,avg in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['MinDays'],df['avg_sales_box_day']):\n",
    "    if inv <= 0:\n",
    "        if stg == 'shortage' :\n",
    "            if ot == 'normal':\n",
    "                gap_box_s3.append(max(mi*avg - pgi - inv,0))\n",
    "            elif ot == 'under': \n",
    "                gap_box_s3.append(max(order-pgi-inv,0))\n",
    "            elif ot == 'over' and pt !='exceeded': \n",
    "                gap_box_s3.append(max(mi*avg - pgi - inv,0))\n",
    "            else:\n",
    "                gap_box_s3.append(None)\n",
    "        else:\n",
    "            gap_box_s3.append(None)\n",
    "    else:\n",
    "        gap_box_s3.append(None)\n",
    "\n",
    "df['gap_box_s3'] = gap_box_s3\n",
    "df['gap_box_s3'].sum().astype(int) # 65,147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculate gap can be fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAP and exceed pgi amount group by year, week, material and plant \n",
    "sku_gap_fill = df[['year','week','material','Category','Plnt','gap_box_s1','gap_box_s2','gap_box_s3','exceed_pgi_box']]\\\n",
    "                    .groupby(['year','week','material','Plnt'])\\\n",
    "                    .agg({'gap_box_s1':'sum','gap_box_s2':'sum','gap_box_s3':'sum','exceed_pgi_box':'sum','Category':'count'}).reset_index()\n",
    "sku_gap_fill.rename(columns ={'Category':'count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gap \n",
    "gap_can_be_fill_s1 = []\n",
    "gap_can_be_fill_s2 = []\n",
    "gap_can_be_fill_s3 = []\n",
    "\n",
    "for g1, g2, g3, e in zip(sku_gap_fill['gap_box_s1'],sku_gap_fill['gap_box_s2'],sku_gap_fill['gap_box_s3'],sku_gap_fill['exceed_pgi_box']):\n",
    "    gap_can_be_fill_s1.append(min(g1,e))\n",
    "    gap_can_be_fill_s2.append(min(g2,e))\n",
    "    gap_can_be_fill_s3.append(min(g3,e))\n",
    "    \n",
    "\n",
    "sku_gap_fill['gap_can_be_fill_s1'] = gap_can_be_fill_s1\n",
    "sku_gap_fill['gap_can_be_fill_s2'] = gap_can_be_fill_s2\n",
    "sku_gap_fill['gap_can_be_fill_s3'] = gap_can_be_fill_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gap fill index \n",
    "sku_gap_fill['gap_fill_index_s1'] = (sku_gap_fill['gap_can_be_fill_s1']/sku_gap_fill['gap_box_s1']).replace(np.inf, 0)\n",
    "sku_gap_fill['gap_fill_index_s2'] = (sku_gap_fill['gap_can_be_fill_s2']/sku_gap_fill['gap_box_s2']).replace(np.inf, 0)\n",
    "sku_gap_fill['gap_fill_index_s3'] = (sku_gap_fill['gap_can_be_fill_s3']/sku_gap_fill['gap_box_s3']).replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map index back to df\n",
    "df1 = pd.merge(df, sku_gap_fill[['year','week','material','Plnt','gap_fill_index_s1','gap_fill_index_s2','gap_fill_index_s3']],\n",
    "               on=['year','week','material','Plnt'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27073617.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27073617.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gap_box_can_be_fill_s1        213561\n",
       "gap_box_can_be_fill_s2        148980\n",
       "gap_box_can_be_fill_s3         39377\n",
       "gap_can_be_fill_value_s1    29384480\n",
       "gap_can_be_fill_value_s2    20116256\n",
       "gap_can_be_fill_value_s3     5681241\n",
       "dtype: int32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate gap can be fill value\n",
    "gap_box_can_be_fill_s1 = []\n",
    "gap_box_can_be_fill_s2 = []\n",
    "gap_box_can_be_fill_s3 = []\n",
    "gap_can_be_fill_value_s1 = []\n",
    "gap_can_be_fill_value_s2 = []\n",
    "gap_can_be_fill_value_s3 = []\n",
    "\n",
    "\n",
    "for ot,pt,stg,g1,g2,g3,ix1,ix2,ix3,price in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],\n",
    "                                                df1['gap_box_s1'],df1['gap_box_s2'],df1['gap_box_s3'],\n",
    "                                                df1['gap_fill_index_s1'],df1['gap_fill_index_s2'],df1['gap_fill_index_s3'],df1['Net price']):\n",
    "    if stg == 'shortage' and pt != 'exceeded':\n",
    "        # calculate gap box can be fill\n",
    "        gap_box_can_be_fill_s1.append(g1*ix1)\n",
    "        gap_box_can_be_fill_s2.append(g2*ix2)\n",
    "        gap_box_can_be_fill_s3.append(g3*ix3)\n",
    "        \n",
    "        # calculate gap box value\n",
    "        gap_can_be_fill_value_s1.append(g1*ix1*price)\n",
    "        gap_can_be_fill_value_s2.append(g2*ix2*price)\n",
    "        gap_can_be_fill_value_s3.append(g3*ix3*price)\n",
    "    else:\n",
    "        gap_box_can_be_fill_s1.append(None)\n",
    "        gap_box_can_be_fill_s2.append(None)\n",
    "        gap_box_can_be_fill_s3.append(None)\n",
    "        \n",
    "        gap_can_be_fill_value_s1.append(None)\n",
    "        gap_can_be_fill_value_s2.append(None)\n",
    "        gap_can_be_fill_value_s3.append(None)\n",
    "        \n",
    "df1['gap_box_can_be_fill_s1'] = gap_box_can_be_fill_s1\n",
    "df1['gap_box_can_be_fill_s2'] = gap_box_can_be_fill_s2\n",
    "df1['gap_box_can_be_fill_s3'] = gap_box_can_be_fill_s3\n",
    "df1['gap_can_be_fill_value_s1'] = gap_can_be_fill_value_s1\n",
    "df1['gap_can_be_fill_value_s2'] = gap_can_be_fill_value_s2\n",
    "df1['gap_can_be_fill_value_s3'] = gap_can_be_fill_value_s3\n",
    "\n",
    "# Calculate the sum\n",
    "df1[['gap_box_can_be_fill_s1','gap_box_can_be_fill_s2','gap_box_can_be_fill_s3',\n",
    "     'gap_can_be_fill_value_s1','gap_can_be_fill_value_s2','gap_can_be_fill_value_s3']].sum().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Calculate reallocated exceed pgi to fill the gap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAP can be fill and exceed pgi amount group by year, week, material and plant\n",
    "        # Applied in adjusted order\n",
    "sku_exceed_reallocate = df1[['year','week','material','Plnt','exceed_pgi_box'\n",
    "                             ,'gap_box_can_be_fill_s1','gap_box_can_be_fill_s2','gap_box_can_be_fill_s3']]\\\n",
    "                                .groupby(['year','week','material','Plnt'])\\\n",
    "                                 .agg({'gap_box_can_be_fill_s1':'sum','gap_box_can_be_fill_s2':'sum','gap_box_can_be_fill_s3':'sum','exceed_pgi_box':'sum'}).reset_index()\n",
    "\n",
    "# calculate exceed index \n",
    "sku_exceed_reallocate['exceed_fill_index_s1'] = (sku_exceed_reallocate['gap_box_can_be_fill_s1']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "sku_exceed_reallocate['exceed_fill_index_s2'] = (sku_exceed_reallocate['gap_box_can_be_fill_s2']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "sku_exceed_reallocate['exceed_fill_index_s3'] = (sku_exceed_reallocate['gap_box_can_be_fill_s3']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "\n",
    "# Map index back to df1\n",
    "df1 = pd.merge(df1, sku_exceed_reallocate[['year','week','material','Plnt','exceed_fill_index_s1','exceed_fill_index_s2','exceed_fill_index_s3']],\n",
    "               on=['year','week','material','Plnt'],how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Calculate adjusted order qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23539577"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_order_qty = []\n",
    "\n",
    "for ot,pt,stg,order,inv,mx,avg,sale in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],df1['Order Qty'],\n",
    "                                      df1['avail_inventory_box'],df1['MaxDays'],df1['avg_sales_box_day'],df1['sale_month']):\n",
    "    if stg == 'shortage' and ot == 'over':\n",
    "        if inv > mx*avg: # Case 1: conside max boundary\n",
    "            aj_order_a = 0\n",
    "        else: # inv <= mx*avg\n",
    "            aj_order_a = mx*avg - inv\n",
    "        if order + inv > sale: # Case 2: consider following month sale\n",
    "            aj_order_b = sale - inv\n",
    "        else:\n",
    "            aj_order_b = order\n",
    "        adjusted_order_qty.append(max(aj_order_a, aj_order_b))\n",
    "    else:\n",
    "        adjusted_order_qty.append(order)\n",
    "        \n",
    "df1['adjusted_order_qty'] = adjusted_order_qty\n",
    "df1['adjusted_order_qty'].sum().astype(int) #23,539,577"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Calculate adjusted pgi qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adjusted_confirm_qty_s1    23079332\n",
       "adjusted_confirm_qty_s2    23015569\n",
       "adjusted_confirm_qty_s3    22905781\n",
       "dtype: int32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill na with 0 for new cols\n",
    "qualitative,quantitative = qual_quant_features(df1)\n",
    "df1[quantitative] = df1[quantitative].fillna(0)\n",
    "\n",
    "adjusted_confirm_qty_s1 = []\n",
    "adjusted_confirm_qty_s2 = []\n",
    "adjusted_confirm_qty_s3 = []\n",
    "\n",
    "for ot,pt,stg,aj_order,pgi,gap1,gap2,gap3,ex, ex_ix1,ex_ix2,ex_ix3 \\\n",
    "    in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],df1['adjusted_order_qty'],df1['ConfirmQty'],\n",
    "           df1['gap_box_can_be_fill_s1'],df1['gap_box_can_be_fill_s2'],df1['gap_box_can_be_fill_s3'],\n",
    "           df1['exceed_pgi_box'],df1['exceed_fill_index_s1'],df1['exceed_fill_index_s2'],df1['exceed_fill_index_s3']):\n",
    "        \n",
    "        if stg == 'normal':\n",
    "            adjusted_confirm_qty_s1.append(pgi)\n",
    "            adjusted_confirm_qty_s2.append(pgi)\n",
    "            adjusted_confirm_qty_s3.append(pgi)\n",
    "            \n",
    "        elif stg == 'shortage' and pt != 'exceeded':\n",
    "            adjusted_confirm_qty_s1.append(min(pgi+gap1, aj_order))\n",
    "            adjusted_confirm_qty_s2.append(min(pgi+gap2, aj_order))\n",
    "            adjusted_confirm_qty_s3.append(min(pgi+gap3, aj_order))\n",
    "            \n",
    "        elif stg == 'shortage' and pt == 'exceeded':\n",
    "            adjusted_confirm_qty_s1.append(min(pgi-ex*ex_ix1, aj_order))\n",
    "            adjusted_confirm_qty_s2.append(min(pgi-ex*ex_ix2, aj_order))\n",
    "            adjusted_confirm_qty_s3.append(min(pgi-ex*ex_ix3, aj_order))\n",
    "            \n",
    "\n",
    "df1['adjusted_confirm_qty_s1'] = adjusted_confirm_qty_s1\n",
    "df1['adjusted_confirm_qty_s2'] = adjusted_confirm_qty_s2\n",
    "df1['adjusted_confirm_qty_s3'] = adjusted_confirm_qty_s3\n",
    "\n",
    "df1[['adjusted_confirm_qty_s1','adjusted_confirm_qty_s2','adjusted_confirm_qty_s3']].sum().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Calculate the benefit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drive_sale_s1     7346120\n",
       "drive_sale_s2    10058128\n",
       "drive_sale_s3     5681241\n",
       "dtype: int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_sale_s1 = []\n",
    "drive_sale_s2 = []\n",
    "drive_sale_s3 = []\n",
    "\n",
    "s1_index = 0.25\n",
    "s2_index = 0.5\n",
    "s3_index = 1\n",
    "\n",
    "for ot,pt,stg,gv1,gv2,gv3 in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],\n",
    "                                        df1['gap_can_be_fill_value_s1'],df1['gap_can_be_fill_value_s2'],df1['gap_can_be_fill_value_s3']):\n",
    "        if stg == 'shortage' and pt != 'exceed':\n",
    "            drive_sale_s1.append(s1_index*gv1)\n",
    "            drive_sale_s2.append(s2_index*gv2)\n",
    "            drive_sale_s3.append(s3_index*gv3)\n",
    "        else: \n",
    "            drive_sale_s1.append(None)\n",
    "            drive_sale_s2.append(None)\n",
    "            drive_sale_s3.append(None)\n",
    "            \n",
    "df1['drive_sale_s1']=drive_sale_s1\n",
    "df1['drive_sale_s2']=drive_sale_s2\n",
    "df1['drive_sale_s3']=drive_sale_s3\n",
    "df1[['drive_sale_s1','drive_sale_s2','drive_sale_s3']].sum().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortage</th>\n",
       "      <th>original_cfr</th>\n",
       "      <th>adjusted_cfr_s1</th>\n",
       "      <th>adjusted_cfr_s2</th>\n",
       "      <th>adjusted_cfr_s3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>99.694992</td>\n",
       "      <td>99.694992</td>\n",
       "      <td>99.694992</td>\n",
       "      <td>99.694992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shortage</td>\n",
       "      <td>89.336637</td>\n",
       "      <td>93.437503</td>\n",
       "      <td>92.410353</td>\n",
       "      <td>90.641773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shortage  original_cfr  adjusted_cfr_s1  adjusted_cfr_s2  adjusted_cfr_s3\n",
       "0    normal     99.694992        99.694992        99.694992        99.694992\n",
       "1  shortage     89.336637        93.437503        92.410353        90.641773"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cfr = df1[['order_type','pgi_type','shortage','Order Qty','ConfirmQty','adjusted_order_qty','adjusted_confirm_qty_s1','adjusted_confirm_qty_s2','adjusted_confirm_qty_s3']]\n",
    "\n",
    "df_cfr_groupby_shortage = df_cfr.groupby(['shortage']).sum().reset_index()\n",
    "\n",
    "df_cfr_groupby_shortage['original_cfr'] = df_cfr_groupby_shortage['ConfirmQty']/df_cfr_groupby_shortage['Order Qty']*100\n",
    "df_cfr_groupby_shortage['adjusted_cfr_s1'] = df_cfr_groupby_shortage['adjusted_confirm_qty_s1']/df_cfr_groupby_shortage['adjusted_order_qty']*100\n",
    "df_cfr_groupby_shortage['adjusted_cfr_s2'] = df_cfr_groupby_shortage['adjusted_confirm_qty_s2']/df_cfr_groupby_shortage['adjusted_order_qty']*100\n",
    "df_cfr_groupby_shortage['adjusted_cfr_s3'] = df_cfr_groupby_shortage['adjusted_confirm_qty_s3']/df_cfr_groupby_shortage['adjusted_order_qty']*100\n",
    "\n",
    "df_cfr_groupby_shortage[['shortage','original_cfr','adjusted_cfr_s1','adjusted_cfr_s2','adjusted_cfr_s3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv(r'C:\\Users\\the7490\\Downloads\\kunlun_v1.csv',encoding='gbk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
