{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the7490\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\Users\\the7490\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime \n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import qgrid\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing\n",
    "## 1.1 Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAP VA05 File ---\n",
    "#File path\n",
    "va_file_dir = r'C:\\Users\\the7490\\MDLZ\\Central Analytics Team CAT - Projects\\Beta Quadrant\\KUNLUN\\01.Raw Data\\VA05_CSV'\n",
    "\n",
    "#get file name list\n",
    "va_file_list = os.listdir(va_file_dir)\n",
    "new_list = []\n",
    "\n",
    "\n",
    "for file in va_file_list:\n",
    "    #construct file path\n",
    "    file_path = os.path.join(va_file_dir,file)\n",
    "    \n",
    "    df = pd.read_csv(file_path , encoding = 'utf-8',thousands= r',')\n",
    "    \n",
    "    df['Doc. Date'] = pd.to_datetime(df['Doc. Date'])\n",
    "\n",
    "    df = df.rename(columns=lambda x: x.strip())\n",
    "    \n",
    "    new_list.append(df)\n",
    "    # print(file)\n",
    "    \n",
    "#Combine data\n",
    "va = pd.concat(new_list)\n",
    "\n",
    "# --- CRS data ---\n",
    "# file_dir = r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\crs_order'\n",
    "# file_list = os.listdir(file_dir)\n",
    "# new_list = []\n",
    "\n",
    "# for file in file_list:\n",
    "#     file_path = os.path.join(file_dir,file)\n",
    "#     dataframe = pd.read_csv(file_path)\n",
    "#     new_list.append(dataframe)\n",
    "    \n",
    "# #Combine data\n",
    "# crs = pd.concat(new_list)\n",
    "crs = pd.read_csv(r'C:\\Users\\the7490\\Downloads\\crs_updated_following.csv',encoding='utf-8')\n",
    "\n",
    "# --- Boundary data ---\n",
    "file_dir = r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\min_max_intentory_date'\n",
    "\n",
    "\n",
    "file_list = os.listdir(file_dir)\n",
    "new_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(file_dir,file)\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    new_list.append(dataframe)\n",
    "\n",
    "    \n",
    "boundary = pd.concat(new_list)\n",
    "\n",
    "# SKU mapping - Master\n",
    "sku_mapping = pd.read_excel(r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\SKU Category Mapping List V2.xlsx', engine = \"xlrd\")\n",
    "sku_mapping = sku_mapping[['sku_code','Category']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qual_quant_features(data):\n",
    "    dtypes = list(map(lambda x:str(x),list(data.dtypes)))\n",
    "    qualitative = []\n",
    "    quantitative = []\n",
    "    for i in range(len(dtypes)):\n",
    "        if dtypes[i] == 'object':\n",
    "            qualitative.append(data.columns[i])\n",
    "        else:\n",
    "            quantitative.append(data.columns[i])\n",
    "    return qualitative,quantitative\n",
    "\n",
    "qualitative,quantitative = qual_quant_features(va)\n",
    "\n",
    "# Create a function to show result\n",
    "def result_show(path):\n",
    "    return qgrid.show_grid(path,show_toolbar = True)\n",
    "\n",
    "def trim(df):\n",
    "    df_obj = df.select_dtypes(['object'])\n",
    "    df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip()) #trim\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Clean Data - SAP VA05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAP处理考虑int\n",
    "# Filter out wanted columns and set data types\n",
    "va_df = va[['Rj','PO Number','Sold-To Pt','Name 1','Material','Description','Plnt','Order Qty','ConfirmQty','Doc. Date','Cust.price','Net price','SaTy']]\n",
    "# va_df = va_df[va_df['Order Qty']>0]\n",
    "\n",
    "# va_df[['Sold-To Pt','Material']] = va_df[['Sold-To Pt','Material']].astype(float).astype(int).astype(str)\n",
    "# va_df = va_df[~va_df['Material'].str.contains(r'DM')]\n",
    "# va_df[['Material']] = va_df[['Material']].astype(float)\n",
    "\n",
    "# Remove na material rows\n",
    "# va_df = va_df[~va_df['Material'].isna()]\n",
    "\n",
    "va_df[['Material','Sold-To Pt']] = va_df[['Material','Sold-To Pt']].astype(str)\n",
    "\n",
    "va_df[['Order Qty','ConfirmQty']] = va_df[['Order Qty','ConfirmQty']].fillna(0).astype(int)\n",
    "\n",
    "# Saty == ZOR  and PO number start with VZO for CRS customer\n",
    "va_df =  va_df[va_df['SaTy']=='ZOR']\n",
    "va_df = va_df[va_df['PO Number'].str.contains(r'VZO*')]\n",
    "\n",
    "# Replace null with 0 for Rj\n",
    "va_df['Rj'] = va_df['Rj'].fillna(0).astype(int)\n",
    "\n",
    "# trim\n",
    "va_df = trim(va_df)\n",
    "\n",
    "# Remove 61 code\n",
    "va_df = va_df[va_df['Rj']!= 61]\n",
    "\n",
    "# Set Rj=10 if order_qty > confrimQty and Rj is null\n",
    "# va_df['Rj'] = va_df[['Order Qty','ConfirmQty','Rj']].apply(lambda x: 10 if x['Rj']== 0 and x['Order Qty']> x['ConfirmQty'] else x['Rj'], axis =1)\n",
    "\n",
    "# Gourp by Customer, Material, Date to map CRS data and count \n",
    "va_df_grouped = va_df[['Order Qty','ConfirmQty','Sold-To Pt','Material','Doc. Date','Rj']].groupby([\"Sold-To Pt\",'Material','Doc. Date']).agg({'Order Qty':'sum','ConfirmQty':'sum','Rj':'count'}).reset_index()\n",
    "va_df_grouped.rename(columns ={'Rj':'count'}, inplace = True)\n",
    "\n",
    "\n",
    "# Get Customer and SKU Info\n",
    "va_cus = va_df[[\"Sold-To Pt\",'Name 1','Plnt']].drop_duplicates(subset=['Sold-To Pt'],keep='first',inplace=False)\n",
    "va_df_grouped_cus = pd.merge(va_df_grouped, va_cus, on = 'Sold-To Pt',how = 'left')\n",
    "\n",
    "va_sku = va_df[[\"Material\",'Description','Net price']].drop_duplicates(subset=['Material'],keep='first',inplace=False)\n",
    "df_va = pd.merge(va_df_grouped_cus, va_sku, on = 'Material',how = 'left')\n",
    "\n",
    "# df_va =  pd.merge(df_va, date[['Date','year','week']], left_on = 'Doc. Date',right_on = 'Date',how = 'left') \n",
    "df_va['year'] = df_va['Doc. Date'].dt.year.astype(int)\n",
    "df_va['week'] = df_va['Doc. Date'].apply(lambda x: x.strftime(\"%W\")).astype(int) # Start from Monday\n",
    "df_va['ds'] = df_va['Doc. Date'].apply(lambda x: x.strftime(\"%Y%m%d\")).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_va['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Clean data - CRS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted_columns\n",
    "crs = crs.drop(columns = ['Unnamed: 0','year','week'])\n",
    "\n",
    "# Replace \\N with null\n",
    "crs = crs.replace({r'\\N': None})\n",
    "\n",
    "# Set data type\n",
    "crs['calc_date'] = pd.to_datetime(crs['calc_date'])\n",
    "crs[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5']] = crs[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5']].astype(float)\n",
    "crs[['sale_week','sale_week1','sale_week2','sale_week3','sale_week4']] = crs[['sale_week','sale_week1','sale_week2','sale_week3','sale_week4']].astype(float)\n",
    "\n",
    "crs[['sold_to_pt','material','ds']] = crs[['sold_to_pt','material','ds']].astype(str)\n",
    "crs[['order_qty','pgi_qty']] = crs[['order_qty','pgi_qty']].astype(int)\n",
    "\n",
    "crs = trim(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Clean data - boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary.drop_duplicates(subset=['CategoryName','ReceiverCode'], keep='first',inplace=True)\n",
    "boundary = boundary.drop(columns=['CategoryCode','HotFlag','ReceiverName', 'InsertTime'])\n",
    "boundary[['ReceiverCode']] = boundary[['ReceiverCode']].astype(str)\n",
    "boundary = trim(boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge crs and va\n",
    "va_crs = pd.merge(df_va, crs,left_on=['Sold-To Pt','Material','ds'],right_on=['sold_to_pt','material','ds'], how='left')\n",
    "\n",
    "# merge sku mapping to get category \n",
    "va_crs_sku = pd.merge(va_crs, sku_mapping,left_on=['material'],right_on=['sku_code'],how='left')\n",
    "\n",
    "#  merge boundary\n",
    "va_crs_sku_bdy = pd.merge(va_crs_sku, boundary,left_on=['sold_to_pt','Category'],right_on=['ReceiverCode','CategoryName'],how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Organize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = va_crs_sku_bdy\n",
    "\n",
    "# Fill NA min as 14 and max as 28\n",
    "df_prep['MinDays'] = df_prep['MinDays'].replace(np.nan, 14).astype(int)\n",
    "df_prep['MaxDays'] = df_prep['MaxDays'].replace(np.nan, 28).astype(int)\n",
    "\n",
    "# keep records of ordered date only\n",
    "df_prep = df_prep[df_prep['order_qty']>0]\n",
    "# df_prep = df_prep[df_prep['Order Qty']>0]\n",
    "\n",
    "\n",
    "# remove avg_sale < 0\n",
    "df_prep = df_prep[df_prep['avg_sales_box_day']>0]\n",
    "\n",
    "# remove duplicated columns\n",
    "df_prep = df_prep.drop(columns=['sold_to_pt','material','sku_code','ReceiverCode','calc_date'])\n",
    "\n",
    "# set data type and  replace fill na with 0\n",
    "df_prep[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5','sale_week1','sale_week2',\n",
    "         'sale_week3','sale_week4','sale_week']] = \\\n",
    "df_prep[['suggest_box','sale_box_week1','sale_box_week2','sale_box_week3','sale_box_week4','sale_box_week5','sale_week1','sale_week2','sale_week3','sale_week4','sale_week']].fillna(0).astype(float)\n",
    "\n",
    "# df_prep['sale_month'] = (df_prep['sale_box_week1']+ df_prep['sale_box_week2']+ df_prep['sale_box_week3']+ df_prep['sale_box_week4'])\n",
    "df_prep['sale_month'] = (df_prep['sale_week1']+ df_prep['sale_week2']+ df_prep['sale_week3']+ df_prep['sale_week4'])\n",
    "\n",
    "# rename columns \n",
    "df_prep = df_prep.rename(columns = {'Sold-To Pt':'sold_to_pt','Material':'material'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep['MaxDays'] = df_prep['MaxDays']*1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Tag - CRS + KA SAP CFR 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply shortage tag via CRS data including reason code 61 (customer real need)\n",
    "# SAP data starts from 2020\n",
    "crs['year'] = crs['calc_date'].dt.year.astype(int)\n",
    "crs['week'] = crs['calc_date'].apply(lambda x: x.strftime(\"%W\")).astype(int)   #Start from Monday\n",
    "crs_incl_61 = crs\n",
    "\n",
    "crs_incl_61 = crs_incl_61[['order_qty','pgi_qty','year','week','material']].groupby(['year','week','material']).sum().reset_index()\n",
    "\n",
    "# CFR < 94% → shorage\n",
    "crs_incl_61['Shortage_incl_61'] = crs_incl_61[['order_qty','pgi_qty']].apply(lambda x: 'shortage' if x['pgi_qty']/x['order_qty'] < 0.94 else 'normal', axis = 1)\n",
    "\n",
    "# merge\n",
    "# df_prep = pd.merge(df_prep, crs_incl_61[['year','week','material','Shortage_incl_61']], on = ['year','week','material'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define order and pgi type\n",
    "def assign_order_type(df):\n",
    "    order = df['Order Qty']\n",
    "    inv = df['avail_inventory_box']\n",
    "    ts = df['intrans_inventory_box']\n",
    "    mx = df['MaxDays']\n",
    "    mi = df['MinDays']\n",
    "    avg = df['avg_sales_box_day']\n",
    "    \n",
    "    if order+inv +ts > mx*avg :\n",
    "        return 'over'\n",
    "    elif order+inv + ts < mi*avg :\n",
    "        return 'under'\n",
    "    else: # order+inv between(mi*avg, mx*avg)\n",
    "        return 'normal'\n",
    "    \n",
    "def assign_pgi_type(df):\n",
    "    pgi = df['ConfirmQty']\n",
    "    inv = df['avail_inventory_box']\n",
    "    ts = df['intrans_inventory_box']\n",
    "    mx = df['MaxDays']\n",
    "    mi = df['MinDays']\n",
    "    avg = df['avg_sales_box_day']\n",
    "    \n",
    "    if pgi+inv +ts > mx*avg :\n",
    "        return 'exceeded'\n",
    "    elif pgi+inv +ts < mi*avg :\n",
    "        return 'lacking'\n",
    "    else: # pgi+inv between(mi*avg, mx*avg)\n",
    "        return 'normal'\n",
    "    \n",
    "df_prep['order_type'] = df_prep.apply(assign_order_type,axis=1)\n",
    "df_prep['pgi_type'] = df_prep.apply(assign_pgi_type,axis=1)\n",
    "\n",
    "#df_prep.rename(columns = {'Shortage_incl_61': 'shortage'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crs = df_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *1.6 Add KA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_cus = pd.read_csv(r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\dim_customer_atom.csv',encoding='gbk')\n",
    "\n",
    "\n",
    "ka = ka_cus[['sold_to_code','ka_type_bc']].astype(str)\n",
    "ka = ka[ka['ka_type_bc'].str.contains(r'NKA|LKA',regex=True)]\n",
    "ka_list =ka[['sold_to_code']].drop_duplicates().astype(int)\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for cus in zip(ka_list['sold_to_code']):\n",
    "    temp = va[va['Sold-To Pt']==cus]\n",
    "    temp_list.append(temp)\n",
    "    \n",
    "va_ka = pd.concat(temp_list)\n",
    "\n",
    "# keep records of ordered date only\n",
    "va_ka = va_ka[va_ka['Order Qty']>0]\n",
    "\n",
    "va_ka['Rj'] = va_ka['Rj'].fillna(0).astype(int)\n",
    "\n",
    "va_ka[['Sold-To Pt','Material']] = va_ka[['Sold-To Pt','Material']].astype(float).astype(int).astype(str)\n",
    "\n",
    "va_ka = trim(va_ka)\n",
    "\n",
    "# remove 61!!!\n",
    "va_ka = va_ka[va_ka['Rj']!= 61]\n",
    "\n",
    "# Remove na material rows\n",
    "va_ka = va_ka[~va_ka['Material'].isna()]\n",
    "\n",
    "va_ka[['Material','Sold-To Pt']] = va_ka[['Material','Sold-To Pt']].astype(str)\n",
    "\n",
    "# Gourp by Customer, Material, Date to map CRS data and count \n",
    "va_ka_grouped = va_ka[['Order Qty','ConfirmQty','Sold-To Pt','Material','Doc. Date','PO Number']].groupby([\"Sold-To Pt\",'Material','Doc. Date']).agg({'Order Qty':'sum','ConfirmQty':'sum','PO Number':'count'}).reset_index()\n",
    "va_ka_grouped.rename(columns ={'PO Number':'count'}, inplace = True)\n",
    "\n",
    "\n",
    "# Get Customer and SKU Info\n",
    "va_ka_cus = va_ka[[\"Sold-To Pt\",'Name 1','Plnt']].drop_duplicates(subset=['Sold-To Pt'],keep='first',inplace=False)\n",
    "va_ka_info = pd.merge(va_ka_grouped, va_ka_cus, on = 'Sold-To Pt',how = 'left')\n",
    "\n",
    "va_ka_sku = va_ka[[\"Material\",'Description','Net price']].drop_duplicates(subset=['Material'],keep='first',inplace=False)\n",
    "df_ka = pd.merge(va_ka_info, va_ka_sku, on = 'Material',how = 'left')\n",
    "\n",
    "# df_va =  pd.merge(df_va, date[['Date','year','week']], left_on = 'Doc. Date',right_on = 'Date',how = 'left') \n",
    "df_ka['year'] = df_ka['Doc. Date'].dt.year.astype(int)\n",
    "df_ka['week'] = df_ka['Doc. Date'].apply(lambda x: x.strftime(\"%W\")).astype(int)    # Start from Monday  \n",
    "df_ka['ds'] = df_ka['Doc. Date'].apply(lambda x: x.strftime(\"%Y%m%d\")).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ka['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ka_tag['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag update\n",
    "df_ka_tag = df_ka\n",
    "df_ka_tag.rename(columns = {'Sold-To Pt':'sold_to_pt','Material':'material'}, inplace = True)\n",
    "df_ka_tag[['sold_to_pt','material']] = df_ka_tag[['sold_to_pt','material']].astype(str)\n",
    "\n",
    "# Tag pgi type\n",
    "df_ka_tag['pgi_type'] = df_ka_tag[['Order Qty','ConfirmQty']].apply(lambda x: 'lacking' if x['Order Qty']>x['ConfirmQty'] else 'normal',axis=1)\n",
    "\n",
    "# Do not assign order type for KA as we don't sugget order qty for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## *1.7 Append \n",
    "df_crs['CusType'] = 'CRS'\n",
    "df_ka_tag['CusType']='KA'\n",
    "df = df_crs.append(df_ka_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_ka_tag = pd.concat(temp_list)\n",
    "\n",
    "# keep records of ordered date only\n",
    "va_ka_tag = va_ka_tag[va_ka_tag['Order Qty']>0]\n",
    "\n",
    "va_ka_tag['Rj'] = va_ka_tag['Rj'].fillna(0).astype(int)\n",
    "\n",
    "va_ka_tag[['Sold-To Pt','Material']] = va_ka_tag[['Sold-To Pt','Material']].astype(float).astype(int).astype(str)\n",
    "\n",
    "va_ka_tag = trim(va_ka_tag)\n",
    "\n",
    "\n",
    "# Remove na material rows\n",
    "va_ka_tag = va_ka_tag[~va_ka_tag['Material'].isna()]\n",
    "\n",
    "va_ka_tag[['Material','Sold-To Pt']] = va_ka_tag[['Material','Sold-To Pt']].astype(str)\n",
    "\n",
    "va_ka_tag.rename(columns = {'Sold-To Pt':'sold_to_pt','Material':'material'}, inplace = True)\n",
    "va_ka_tag[['sold_to_pt','material']] = va_ka_tag[['sold_to_pt','material']].astype(str)\n",
    "# # Gourp by Customer, Material, Date to map CRS data and count \n",
    "# va_ka_grouped = va_ka[['Order Qty','ConfirmQty','Sold-To Pt','Material','Doc. Date','PO Number']].groupby([\"Sold-To Pt\",'Material','Doc. Date']).agg({'Order Qty':'sum','ConfirmQty':'sum','PO Number':'count'}).reset_index()\n",
    "# va_ka_grouped.rename(columns ={'PO Number':'count'}, inplace = True)\n",
    "\n",
    "\n",
    "# # Get Customer and SKU Info\n",
    "# va_ka_cus = va_ka[[\"Sold-To Pt\",'Name 1','Plnt']].drop_duplicates(subset=['Sold-To Pt'],keep='first',inplace=False)\n",
    "# va_ka_info = pd.merge(va_ka_grouped, va_ka_cus, on = 'Sold-To Pt',how = 'left')\n",
    "\n",
    "# va_ka_sku = va_ka[[\"Material\",'Description','Net price']].drop_duplicates(subset=['Material'],keep='first',inplace=False)\n",
    "# df_ka = pd.merge(va_ka_info, va_ka_sku, on = 'Material',how = 'left')\n",
    "\n",
    "# # df_va =  pd.merge(df_va, date[['Date','year','week']], left_on = 'Doc. Date',right_on = 'Date',how = 'left') \n",
    "va_ka_tag['year'] = va_ka_tag['Doc. Date'].dt.year.astype(int)\n",
    "va_ka_tag['week'] = va_ka_tag['Doc. Date'].apply(lambda x: x.strftime(\"%W\")).astype(int)    # Start from Monday  \n",
    "# df_ka['ds'] = df_ka['Doc. Date'].apply(lambda x: x.strftime(\"%Y%m%d\")).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Shoratge tag update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs_incl_61 = crs_incl_61.rename(columns = {'order_qty':'Order Qty','pgi_qty':'ConfirmQty'})\n",
    "crs_incl_61['CusType'] = 'CRS'\n",
    "df_tag = crs_incl_61.append(va_ka_tag)\n",
    "df_tag = df_tag[df_tag['Order Qty']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tag = df_tag[['Order Qty','ConfirmQty','year','week','material']].groupby(['year','week','material']).sum().reset_index()\n",
    "\n",
    "# CFR < 94% → shorage\n",
    "df_tag['shortage'] = df_tag[['Order Qty','ConfirmQty']].apply(lambda x: 'shortage' if x['ConfirmQty']/x['Order Qty'] < 0.94 else 'normal', axis = 1)\n",
    "\n",
    "# tag \n",
    "df = pd.merge(df, df_tag[['year', 'week', 'material', 'shortage']], on=['year','week','material'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge crs by 94% cfr shortage tag\n",
    "df = pd.merge(df, crs_incl_61[['year','week','material','Shortage_incl_61']], on = ['year','week','material'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shortage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Allocation \n",
    "## 2.1 Calculate Gap and exceed amount for shortage records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2391939.0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exceed amount: take both max boundary and following month sale into consideration \n",
    "    # exceed box = pgi - avail_inventory - max( MaxBoundary* avg_sales, sales_month)\n",
    "    # Add transitb\n",
    "exceed_pgi_box = []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,sale,avg,ts in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['sale_month'],df['avg_sales_box_day'],df['intrans_inventory_box']):\n",
    "    if stg == 'shortage' and ot == 'over' and pt == 'exceeded':\n",
    "        if inv + ts > mx*avg:  # Case a:  consider max boundary\n",
    "            ex_a = pgi #exceed = pgi \n",
    "        elif inv+pgi +ts <=mx*avg:\n",
    "            ex_a = 0 # no exceed pgi\n",
    "        else: \n",
    "            ex_a = pgi + inv +ts - mx*avg\n",
    "            \n",
    "        if pgi+inv > sale: # Case b: consider sales in following month,未来一个月的情况考虑在途不公平，在途不能立马转销售\n",
    "            ex_b = pgi+inv-sale # not sell in a month\n",
    "        elif pgi+inv <= sale: #  pgi+inv <= sale sell in a month\n",
    "            ex_b = 0\n",
    "        else:\n",
    "            ex_b = None\n",
    "        exceed_pgi_box.append(int(min(ex_a,ex_b)))\n",
    "    else:\n",
    "        exceed_pgi_box.append(None)\n",
    "\n",
    "        \n",
    "df['exceed_pgi_box'] = exceed_pgi_box \n",
    "\n",
    "df['exceed_pgi_box'].sum()  #3,058,461  / 2,601,679 / transit 3,209,263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45541778.484000005"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Add KA gap for crs shortage sku, gap = order - pgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2408236.0"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenario 1： \n",
    "    # normal/under ordering GAP = order - pgi - avail_inventory - transit\n",
    "    # over orderging and !exceeded pgi type GAP = max boundary * avg_sales, sale_month - pgi - avail_inventory - transit\n",
    "    # 考虑transit\n",
    "gap_box_s1 = []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,mi,avg,cus,ts in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['MinDays'],df['avg_sales_box_day'],df['CusType'],df['intrans_inventory_box']):\n",
    "    if stg == 'shortage'and cus == 'CRS':\n",
    "        if ot != 'over':\n",
    "            gap_box_s1.append(round(max(order - pgi - inv -ts,0)))\n",
    "        elif ot == 'over' and pt !='exceeded': \n",
    "            gap_box_s1.append(round(max(mx*avg - pgi - inv -ts,0)))\n",
    "        else:        \n",
    "            gap_box_s1.append(None)\n",
    "    elif stg == 'shortage' and cus == 'KA':\n",
    "        gap_box_s1.append(round(order-pgi))\n",
    "    else:\n",
    "        gap_box_s1.append(None)\n",
    "        \n",
    "df['gap_box_s1'] = gap_box_s1\n",
    "df['gap_box_s1'].sum() # 443,076 -> 272162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335848.0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['CusType']=='CRS'].gap_box_s1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225509.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenario 2： \n",
    "    # normal GAP = min*avg - pgi - avail_inventory\n",
    "    # under ordering GAP = order - pgi - avail_inventory\n",
    "    # over ordering and !exceeded pgi GAP = min*avg - pgi - avail_inventory\n",
    "gap_box_s2= []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,mi,avg,cus,ts in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['MinDays'],df['avg_sales_box_day'],df['CusType'],df['intrans_inventory_box']):\n",
    "    if stg == 'shortage' and cus == 'CRS':\n",
    "        if ot == 'normal':\n",
    "            gap_box_s2.append(round(max(mi*avg - pgi - inv -ts,0)))\n",
    "        elif ot == 'under': \n",
    "            gap_box_s2.append(round(max(order-pgi-inv -ts,0)))\n",
    "        elif ot == 'over' and pt !='exceeded': \n",
    "            gap_box_s2.append(round(max(mi*avg - pgi - inv -ts,0)))\n",
    "        else:\n",
    "            gap_box_s2.append(None)\n",
    "    elif stg == 'shortage' and cus == 'KA':\n",
    "        gap_box_s2.append(round(order-pgi))      \n",
    "    else:\n",
    "        gap_box_s2.append(None)\n",
    "\n",
    "df['gap_box_s2'] = gap_box_s2\n",
    "df['gap_box_s2'].sum() # 278,806 → 151,841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153121.0"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['CusType']=='CRS'].gap_box_s2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110679.0"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenario 3：OWA/avail_inventory  ==0  \n",
    "    # normal GAP = min*avg - pgi - avail_inventory\n",
    "    # under ordering GAP = order - pgi - avail_inventory\n",
    "    # over ordering and normal pgi GAP = min*avg - pgi - avail_inventory\n",
    "gap_box_s3= []\n",
    "\n",
    "for ot,pt,stg,order,pgi,inv,mx,mi,avg,cus,ts in zip(df['order_type'],df['pgi_type'],df['shortage'],df['Order Qty'],df['ConfirmQty'],df['avail_inventory_box'],df['MaxDays'],df['MinDays'],df['avg_sales_box_day'],df['CusType'],df['intrans_inventory_box']):\n",
    "    if inv <= 0:\n",
    "        if stg == 'shortage' and cus == 'CRS':\n",
    "            if ot == 'normal':\n",
    "                gap_box_s3.append(round(max(mi*avg - pgi - inv -ts,0)))\n",
    "            elif ot == 'under': \n",
    "                gap_box_s3.append(round(max(order-pgi-inv -ts,0)))\n",
    "            elif ot == 'over' and pt !='exceeded': \n",
    "                gap_box_s3.append(round(max(mi*avg - pgi - inv -ts,0)))\n",
    "            else:\n",
    "                gap_box_s3.append(None)\n",
    "        else:\n",
    "            gap_box_s3.append(None)\n",
    "    elif stg == 'shortage' and cus == 'KA':\n",
    "        gap_box_s3.append(round(order-pgi))\n",
    "    else:\n",
    "        gap_box_s3.append(None)\n",
    "\n",
    "df['gap_box_s3'] = gap_box_s3\n",
    "df['gap_box_s3'].sum() # 65,147 ->  37,645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38291.0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['CusType']=='CRS'].gap_box_s3.sum()  #38291"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Align net price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_list = va_df[['Material','Net price']].groupby('Material').agg({'Net price':'mean'}).reset_index()\n",
    "sku_list_ka = va_ka[['Material','Net price']].groupby('Material').agg({'Net price':'mean'}).reset_index()\n",
    "sku_price_list = sku_list.append(sku_list_ka).drop_duplicates('Material').rename(columns = {'Material':'material'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns ='Net price')\n",
    "df = pd.merge(df,sku_price_list, on='material',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2.2 Calculate gap can be fill by customer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAP amount group by year, week, material and plant and customer type\n",
    "df_obj = df.select_dtypes(['object'])\n",
    "df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip()) #trim\n",
    "\n",
    "sku_gap_fill = df[['year','week','material','Plnt','CusType','gap_box_s1','gap_box_s2','gap_box_s3']]\\\n",
    "                    .groupby(['year','week','material','Plnt','CusType'])\\\n",
    "                    .agg({'gap_box_s1':'sum','gap_box_s2':'sum','gap_box_s3':'sum'}).reset_index()\n",
    "sku_gap_fill['key'] = sku_gap_fill['year'].map(str).str.cat([sku_gap_fill['week'].map(str),sku_gap_fill['material'].map(str),sku_gap_fill['Plnt'].map(str)],sep='')\n",
    "\n",
    "\n",
    "# # Exceed by year,week,material,plant and to be disbribute by priority\n",
    "sku_exceed_reallocate = df[['year','week','material','Plnt','exceed_pgi_box']]\\\n",
    "                    .groupby(['year','week','material','Plnt']).agg({'exceed_pgi_box':'sum'}).reset_index()\n",
    "sku_exceed_reallocate['key'] =  sku_exceed_reallocate['year'].map(str).str.cat([sku_exceed_reallocate['week'].map(str),sku_exceed_reallocate['material'].map(str),sku_exceed_reallocate['Plnt'].map(str)],sep='')\n",
    "\n",
    "sku_exceed_gap = pd.merge(sku_gap_fill,sku_exceed_reallocate[['key','exceed_pgi_box']],on=['key'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gap can be fill by Customer Type\n",
    "\n",
    "# 1. KA\n",
    "gap_can_be_fill_s1 = []\n",
    "gap_can_be_fill_s2 = []\n",
    "gap_can_be_fill_s3 = []\n",
    "updated_exceed_pgi_s1 = []\n",
    "updated_exceed_pgi_s2 = []\n",
    "updated_exceed_pgi_s3 = []\n",
    "\n",
    "for key, cus, ex, g1, g2, g3 in zip(sku_exceed_gap['key'],sku_exceed_gap['CusType'],sku_exceed_gap['exceed_pgi_box'],\\\n",
    "                            sku_exceed_gap['gap_box_s1'],sku_exceed_gap['gap_box_s2'],sku_exceed_gap['gap_box_s3']):\n",
    "    if cus == 'KA':\n",
    "        gap_can_be_fill_s1.append(min(g1,ex))\n",
    "        gap_can_be_fill_s2.append(min(g2,ex))\n",
    "        gap_can_be_fill_s3.append(min(g3,ex))\n",
    "        \n",
    "        updated_exceed_pgi_s1.append(ex-min(g1,ex)) # update exceed_pgi\n",
    "        updated_exceed_pgi_s2.append(ex-min(g2,ex))\n",
    "        updated_exceed_pgi_s3.append(ex-min(g3,ex))\n",
    "        \n",
    "    else:\n",
    "        gap_can_be_fill_s1.append(None)\n",
    "        gap_can_be_fill_s2.append(None)\n",
    "        gap_can_be_fill_s3.append(None)\n",
    "        \n",
    "        updated_exceed_pgi_s1.append(None) #只记录更新的exceed\n",
    "        updated_exceed_pgi_s2.append(None)\n",
    "        updated_exceed_pgi_s3.append(None)\n",
    "\n",
    "sku_exceed_gap['gap_can_be_fill_s1'] = gap_can_be_fill_s1\n",
    "sku_exceed_gap['gap_can_be_fill_s2'] = gap_can_be_fill_s2\n",
    "sku_exceed_gap['gap_can_be_fill_s3'] = gap_can_be_fill_s3\n",
    "\n",
    "sku_exceed_gap['updated_exceed_pgi_s1'] = updated_exceed_pgi_s1\n",
    "sku_exceed_gap['updated_exceed_pgi_s2'] = updated_exceed_pgi_s2\n",
    "sku_exceed_gap['updated_exceed_pgi_s3'] = updated_exceed_pgi_s3\n",
    "\n",
    "\n",
    "# update exceed by KA\n",
    "sku_exceed_updated = sku_exceed_gap[sku_exceed_gap['CusType']=='KA']  \n",
    "sku_exceed_updated = sku_exceed_updated[['year','week','material','Plnt','updated_exceed_pgi_s1','updated_exceed_pgi_s2','updated_exceed_pgi_s3']]\\\n",
    "                    .groupby(['year','week','material','Plnt'])\\\n",
    "                    .agg({'updated_exceed_pgi_s1':'sum','updated_exceed_pgi_s2':'sum','updated_exceed_pgi_s3':'sum'}).reset_index()\n",
    "\n",
    "sku_exceed_updated = sku_exceed_updated.rename(columns = {'updated_exceed_pgi_s1':'ka_updated_exceed_pgi_s1',\\\n",
    "                                                          'updated_exceed_pgi_s2':'ka_updated_exceed_pgi_s2',\\\n",
    "                                                          'updated_exceed_pgi_s3':'ka_updated_exceed_pgi_s3',})\n",
    "# sku_exceed_gap = sku_exceed_gap.drop(columns = ['updated_exceed_pgi_s1','updated_exceed_pgi_s2','updated_exceed_pgi_s3'])\n",
    "sku_exceed_gap_updated = pd.merge(sku_exceed_gap,sku_exceed_updated,on=['year','week','material','Plnt'],how='left')\n",
    "sku_exceed_gap_updated['updated_exceed_s1'] = sku_exceed_gap_updated[['exceed_pgi_box','ka_updated_exceed_pgi_s1']].apply(lambda x: x['ka_updated_exceed_pgi_s1'] if x['ka_updated_exceed_pgi_s1']<x['exceed_pgi_box'] else x['exceed_pgi_box'],axis=1 )\n",
    "sku_exceed_gap_updated['updated_exceed_s2'] = sku_exceed_gap_updated[['exceed_pgi_box','ka_updated_exceed_pgi_s2']].apply(lambda x: x['ka_updated_exceed_pgi_s2'] if x['ka_updated_exceed_pgi_s2']<x['exceed_pgi_box'] else x['exceed_pgi_box'],axis=1 )\n",
    "sku_exceed_gap_updated['updated_exceed_s3'] = sku_exceed_gap_updated[['exceed_pgi_box','ka_updated_exceed_pgi_s3']].apply(lambda x: x['ka_updated_exceed_pgi_s3'] if x['ka_updated_exceed_pgi_s3']<x['exceed_pgi_box'] else x['exceed_pgi_box'],axis=1 )\n",
    "\n",
    "\n",
    "# 2. CRS\n",
    "gap_can_be_fill_s1 = []\n",
    "gap_can_be_fill_s2 = []\n",
    "gap_can_be_fill_s3 = []\n",
    "updated_exceed_pgi_s1 = []\n",
    "updated_exceed_pgi_s2 = []\n",
    "updated_exceed_pgi_s3 = []\n",
    "\n",
    "for key,cus,ex1,g1,f1,ex2,g2,f2,ex3,g3,f3 in zip(sku_exceed_gap_updated['key'],sku_exceed_gap_updated['CusType'],\\\n",
    "      sku_exceed_gap_updated['updated_exceed_s1'],sku_exceed_gap_updated['gap_box_s1'],sku_exceed_gap_updated['gap_can_be_fill_s1'],\n",
    "      sku_exceed_gap_updated['updated_exceed_s2'],sku_exceed_gap_updated['gap_box_s2'],sku_exceed_gap_updated['gap_can_be_fill_s2'],\n",
    "      sku_exceed_gap_updated['updated_exceed_s3'],sku_exceed_gap_updated['gap_box_s3'],sku_exceed_gap_updated['gap_can_be_fill_s3']):\n",
    "    \n",
    "    if cus == 'CRS':\n",
    "        gap_can_be_fill_s1.append(min(g1,ex1))\n",
    "        gap_can_be_fill_s2.append(min(g2,ex2))\n",
    "        gap_can_be_fill_s3.append(min(g3,ex3))\n",
    "\n",
    "        updated_exceed_pgi_s1.append(ex1-min(g1,ex1)) # update exceed_pgi\n",
    "        updated_exceed_pgi_s2.append(ex2-min(g2,ex2))\n",
    "        updated_exceed_pgi_s3.append(ex3-min(g3,ex3))\n",
    "    else:\n",
    "        gap_can_be_fill_s1.append(f1)\n",
    "        gap_can_be_fill_s2.append(f2)\n",
    "        gap_can_be_fill_s3.append(f3)\n",
    "\n",
    "        updated_exceed_pgi_s1.append(ex1)\n",
    "        updated_exceed_pgi_s2.append(ex2)\n",
    "        updated_exceed_pgi_s3.append(ex3)\n",
    "\n",
    "sku_exceed_gap_updated['gap_can_be_fill_s1'] = gap_can_be_fill_s1\n",
    "sku_exceed_gap_updated['gap_can_be_fill_s2'] = gap_can_be_fill_s2\n",
    "sku_exceed_gap_updated['gap_can_be_fill_s3'] = gap_can_be_fill_s3\n",
    "sku_exceed_gap_updated['updated_exceed_pgi_s1'] = updated_exceed_pgi_s1\n",
    "sku_exceed_gap_updated['updated_exceed_pgi_s2'] = updated_exceed_pgi_s2\n",
    "sku_exceed_gap_updated['updated_exceed_pgi_s3'] = updated_exceed_pgi_s3\n",
    "\n",
    "# drop assist columns\n",
    "sku_exceed_gap_updated = sku_exceed_gap_updated.drop(columns = ['updated_exceed_s1','updated_exceed_s2','updated_exceed_s3',\\\n",
    "                                                        'ka_updated_exceed_pgi_s1','ka_updated_exceed_pgi_s2','ka_updated_exceed_pgi_s3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_gap_fill = sku_exceed_gap_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gap fill index \n",
    "sku_gap_fill['gap_fill_index_s1'] = (sku_gap_fill['gap_can_be_fill_s1']/sku_gap_fill['gap_box_s1']).replace(np.inf, 0)\n",
    "sku_gap_fill['gap_fill_index_s2'] = (sku_gap_fill['gap_can_be_fill_s2']/sku_gap_fill['gap_box_s2']).replace(np.inf, 0)\n",
    "sku_gap_fill['gap_fill_index_s3'] = (sku_gap_fill['gap_can_be_fill_s3']/sku_gap_fill['gap_box_s3']).replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45541778.484000005"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map index back to df, by year/week/material/plant/customer type\n",
    "df1 = pd.merge(df, sku_gap_fill[['year','week','material','Plnt','CusType','gap_fill_index_s1','gap_fill_index_s2','gap_fill_index_s3']],\n",
    "               on=['year','week','material','Plnt','CusType'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gap_box_can_be_fill_s1        426706\n",
       "gap_box_can_be_fill_s2        383547\n",
       "gap_box_can_be_fill_s3        349995\n",
       "gap_can_be_fill_value_s1    64378343\n",
       "gap_can_be_fill_value_s2    57961679\n",
       "gap_can_be_fill_value_s3    53473356\n",
       "dtype: int32"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate gap can be fill value\n",
    "gap_box_can_be_fill_s1 = []\n",
    "gap_box_can_be_fill_s2 = []\n",
    "gap_box_can_be_fill_s3 = []\n",
    "gap_can_be_fill_value_s1 = []\n",
    "gap_can_be_fill_value_s2 = []\n",
    "gap_can_be_fill_value_s3 = []\n",
    "\n",
    "\n",
    "for ot,pt,stg,g1,g2,g3,ix1,ix2,ix3,price,cus in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],\n",
    "                                                    df1['gap_box_s1'],df1['gap_box_s2'],df1['gap_box_s3'],\n",
    "                                df1['gap_fill_index_s1'],df1['gap_fill_index_s2'],df1['gap_fill_index_s3'],df1['Net price'],df1['CusType']):\n",
    "   \n",
    "    if stg == 'shortage' and pt != 'exceeded':\n",
    "        # calculate gap box can be fill\n",
    "        gap_box_can_be_fill_s1.append(g1*ix1)\n",
    "        gap_box_can_be_fill_s2.append(g2*ix2)\n",
    "        gap_box_can_be_fill_s3.append(g3*ix3)\n",
    "        \n",
    "        # calculate gap box value\n",
    "        gap_can_be_fill_value_s1.append(g1*ix1*price)\n",
    "        gap_can_be_fill_value_s2.append(g2*ix2*price)\n",
    "        gap_can_be_fill_value_s3.append(g3*ix3*price)\n",
    "        \n",
    "    elif stg == 'shortage' and cus == 'KA': #do allocation only for shortage sku\n",
    "        # calculate gap box can be fill\n",
    "        gap_box_can_be_fill_s1.append(g1*ix1)\n",
    "        gap_box_can_be_fill_s2.append(g2*ix2)\n",
    "        gap_box_can_be_fill_s3.append(g3*ix3)\n",
    "        \n",
    "        # calculate gap box value\n",
    "        gap_can_be_fill_value_s1.append(g1*ix1*price)\n",
    "        gap_can_be_fill_value_s2.append(g2*ix2*price)\n",
    "        gap_can_be_fill_value_s3.append(g3*ix3*price)\n",
    "        \n",
    "    else:\n",
    "        gap_box_can_be_fill_s1.append(None)\n",
    "        gap_box_can_be_fill_s2.append(None)\n",
    "        gap_box_can_be_fill_s3.append(None)\n",
    "        \n",
    "        gap_can_be_fill_value_s1.append(None)\n",
    "        gap_can_be_fill_value_s2.append(None)\n",
    "        gap_can_be_fill_value_s3.append(None)\n",
    "        \n",
    "df1['gap_box_can_be_fill_s1'] = gap_box_can_be_fill_s1\n",
    "df1['gap_box_can_be_fill_s2'] = gap_box_can_be_fill_s2\n",
    "df1['gap_box_can_be_fill_s3'] = gap_box_can_be_fill_s3\n",
    "df1['gap_can_be_fill_value_s1'] = gap_can_be_fill_value_s1\n",
    "df1['gap_can_be_fill_value_s2'] = gap_can_be_fill_value_s2\n",
    "df1['gap_can_be_fill_value_s3'] = gap_can_be_fill_value_s3\n",
    "\n",
    "# Calculate the sum\n",
    "df1[['gap_box_can_be_fill_s1','gap_box_can_be_fill_s2','gap_box_can_be_fill_s3',\n",
    "     'gap_can_be_fill_value_s1','gap_can_be_fill_value_s2','gap_can_be_fill_value_s3']].sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dp=df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2.3 Calculate reallocated exceed pgi to fill the gap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAP can be fill and exceed pgi amount group by year, week, material and plant and *CusType\n",
    "        # Applied in adjusted order\n",
    "sku_exceed_reallocate = df1[['year','week','material','Plnt','exceed_pgi_box'\n",
    "                             ,'gap_box_can_be_fill_s1','gap_box_can_be_fill_s2','gap_box_can_be_fill_s3']]\\\n",
    "                                .groupby(['year','week','material','Plnt'])\\\n",
    "                                 .agg({'gap_box_can_be_fill_s1':'sum','gap_box_can_be_fill_s2':'sum','gap_box_can_be_fill_s3':'sum','exceed_pgi_box':'sum'}).reset_index()\n",
    "\n",
    "sku_exceed_reallocate['exceed_pgi_box'] = sku_exceed_reallocate['exceed_pgi_box'].astype(float)\n",
    "\n",
    "# calculate exceed index \n",
    "sku_exceed_reallocate['exceed_fill_index_s1'] = (sku_exceed_reallocate['gap_box_can_be_fill_s1']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "sku_exceed_reallocate['exceed_fill_index_s2'] = (sku_exceed_reallocate['gap_box_can_be_fill_s2']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "sku_exceed_reallocate['exceed_fill_index_s3'] = (sku_exceed_reallocate['gap_box_can_be_fill_s3']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "\n",
    "sku_exceed_reallocate['exceed_can_not_be_allocated_s1'] = sku_exceed_reallocate['exceed_pgi_box']-sku_exceed_reallocate['gap_box_can_be_fill_s1']\n",
    "sku_exceed_reallocate['exceed_can_not_be_allocated_s2'] = sku_exceed_reallocate['exceed_pgi_box']-sku_exceed_reallocate['gap_box_can_be_fill_s2']\n",
    "sku_exceed_reallocate['exceed_can_not_be_allocated_s3'] = sku_exceed_reallocate['exceed_pgi_box']-sku_exceed_reallocate['gap_box_can_be_fill_s3']\n",
    "\n",
    "sku_exceed_reallocate['exceed_back_index_s1'] = (sku_exceed_reallocate['exceed_can_not_be_allocated_s1']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "sku_exceed_reallocate['exceed_back_index_s2'] = (sku_exceed_reallocate['exceed_can_not_be_allocated_s2']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "sku_exceed_reallocate['exceed_back_index_s3'] = (sku_exceed_reallocate['exceed_can_not_be_allocated_s3']/sku_exceed_reallocate['exceed_pgi_box']).replace(np.inf,0)\n",
    "\n",
    "\n",
    "# Map index back to df1\n",
    "df1 = pd.merge(df1, sku_exceed_reallocate[['year','week','material','Plnt','exceed_fill_index_s1','exceed_fill_index_s2','exceed_fill_index_s3','exceed_back_index_s1','exceed_back_index_s2','exceed_back_index_s3']],\n",
    "                           on=['year','week','material','Plnt'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['exceed_fill_index_s1'] = df1[['CusType','exceed_fill_index_s1']].apply(lambda x: 0 if x['CusType']=='KA' else x['exceed_fill_index_s1'],axis=1)\n",
    "df1['exceed_fill_index_s2'] = df1[['CusType','exceed_fill_index_s2']].apply(lambda x: 0 if x['CusType']=='KA' else x['exceed_fill_index_s2'],axis=1)\n",
    "df1['exceed_fill_index_s3'] = df1[['CusType','exceed_fill_index_s3']].apply(lambda x: 0 if x['CusType']=='KA' else x['exceed_fill_index_s3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pgi_after_allocation_s1'] = df1['exceed_pgi_box']*df1['exceed_back_index_s1']\n",
    "df1['pgi_after_allocation_s2'] = df1['exceed_pgi_box']*df1['exceed_back_index_s2']\n",
    "df1['pgi_after_allocation_s3'] = df1['exceed_pgi_box']*df1['exceed_back_index_s3']\n",
    "\n",
    "# drop assistant columns\n",
    "df1 = df1.drop(columns = ['exceed_back_index_s1','exceed_back_index_s2','exceed_back_index_s3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Calculate adjusted order qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42789217"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_order_qty = []\n",
    "\n",
    "for ot,pt,stg,order,inv,mx,avg,sale,cus,ts in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],df1['Order Qty'],\n",
    "                                      df1['avail_inventory_box'],df1['MaxDays'],df1['avg_sales_box_day'],df1['sale_month'],df1['CusType'],df1['intrans_inventory_box']):\n",
    "    if stg == 'shortage' and ot == 'over' and cus == 'CRS':\n",
    "        if inv + ts > mx*avg: # Case 1: conside max boundary\n",
    "            aj_order_a = 0\n",
    "        else: # inv +ts <= mx*avg\n",
    "            aj_order_a = mx*avg - inv -ts\n",
    "        if order + inv  > sale: # Case: consider following month sale\n",
    "            aj_order_b = sale - inv \n",
    "        else:\n",
    "            aj_order_b = order\n",
    "        adjusted_order_qty.append(max(aj_order_a, aj_order_b))\n",
    "    else:\n",
    "        adjusted_order_qty.append(order) # no touch on KA's order\n",
    "        \n",
    "df1['adjusted_order_qty'] = adjusted_order_qty\n",
    "df1['adjusted_order_qty'].sum().astype(int) #23,539,577 → 45,431,958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_order_qty_s1 = []\n",
    "adjusted_order_qty_s2 = []\n",
    "adjusted_order_qty_s3 = []\n",
    "\n",
    "\n",
    "for ot,pt,stg,order,cus,aj,p1,p2,p3 in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],df1['Order Qty'],df1['CusType'],\n",
    "                df1['adjusted_order_qty'],df1['pgi_after_allocation_s1'],df1['pgi_after_allocation_s2'],df1['pgi_after_allocation_s3']):\n",
    "    if stg == 'shortage' and ot == 'over' and cus == 'CRS':\n",
    "        adjusted_order_qty_s1.append(max(aj, order-p1))\n",
    "        adjusted_order_qty_s2.append(max(aj, order-p2))\n",
    "        adjusted_order_qty_s3.append(max(aj, order-p3))\n",
    "\n",
    "    else:\n",
    "        adjusted_order_qty_s1.append(order) # no touch on KA's order\n",
    "        adjusted_order_qty_s2.append(order)\n",
    "        adjusted_order_qty_s3.append(order)\n",
    "        \n",
    "        \n",
    "df1['adjusted_order_qty_s1'] = adjusted_order_qty_s1\n",
    "df1['adjusted_order_qty_s2'] = adjusted_order_qty_s2\n",
    "df1['adjusted_order_qty_s3'] = adjusted_order_qty_s3\n",
    "\n",
    "df1['adjusted_order_qty_s1'].sum().astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Calculate adjusted pgi qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adjusted_confirm_qty_s1    40309340\n",
       "adjusted_confirm_qty_s2    40267448\n",
       "adjusted_confirm_qty_s3    40233866\n",
       "dtype: int32"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill na with 0 for new cols\n",
    "qualitative,quantitative = qual_quant_features(df1)\n",
    "df1[quantitative] = df1[quantitative].fillna(0)\n",
    "\n",
    "adjusted_confirm_qty_s1 = []\n",
    "adjusted_confirm_qty_s2 = []\n",
    "adjusted_confirm_qty_s3 = []\n",
    "\n",
    "for ot,pt,stg,aj1,aj2,aj3,pgi,gap1,gap2,gap3,ex, ex_ix1,ex_ix2,ex_ix3,cus \\\n",
    "    in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],df1['adjusted_order_qty_s1'],df1['adjusted_order_qty_s2'],df1['adjusted_order_qty_s3'],df1['ConfirmQty'],\n",
    "           df1['gap_box_can_be_fill_s1'],df1['gap_box_can_be_fill_s2'],df1['gap_box_can_be_fill_s3'],\n",
    "           df1['exceed_pgi_box'],df1['exceed_fill_index_s1'],df1['exceed_fill_index_s2'],df1['exceed_fill_index_s3'],df1['CusType']):\n",
    "        \n",
    "        if cus == 'CRS':\n",
    "            if stg == 'normal':\n",
    "                adjusted_confirm_qty_s1.append(pgi)\n",
    "                adjusted_confirm_qty_s2.append(pgi)\n",
    "                adjusted_confirm_qty_s3.append(pgi)\n",
    "\n",
    "            elif stg == 'shortage' and pt != 'exceeded':\n",
    "                adjusted_confirm_qty_s1.append(min(pgi+gap1, aj1))\n",
    "                adjusted_confirm_qty_s2.append(min(pgi+gap2, aj2))\n",
    "                adjusted_confirm_qty_s3.append(min(pgi+gap3, aj3))\n",
    "\n",
    "            elif stg == 'shortage' and pt == 'exceeded':\n",
    "                adjusted_confirm_qty_s1.append(min(pgi-ex*ex_ix1, aj1))\n",
    "                adjusted_confirm_qty_s2.append(min(pgi-ex*ex_ix2, aj2))\n",
    "                adjusted_confirm_qty_s3.append(min(pgi-ex*ex_ix3, aj3))\n",
    "                \n",
    "        else: # cus =='KA'\n",
    "            if stg != 'shortage':\n",
    "                adjusted_confirm_qty_s1.append(pgi)\n",
    "                adjusted_confirm_qty_s2.append(pgi)\n",
    "                adjusted_confirm_qty_s3.append(pgi)\n",
    "                \n",
    "            elif stg == 'shortage':\n",
    "                adjusted_confirm_qty_s1.append(pgi+gap1)\n",
    "                adjusted_confirm_qty_s2.append(pgi+gap2)\n",
    "                adjusted_confirm_qty_s3.append(pgi+gap3)\n",
    "\n",
    "\n",
    "df1['adjusted_confirm_qty_s1'] = adjusted_confirm_qty_s1\n",
    "df1['adjusted_confirm_qty_s2'] = adjusted_confirm_qty_s2\n",
    "df1['adjusted_confirm_qty_s3'] = adjusted_confirm_qty_s3\n",
    "\n",
    "df1[['adjusted_confirm_qty_s1','adjusted_confirm_qty_s2','adjusted_confirm_qty_s3']].sum().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Calculate the benefit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortage</th>\n",
       "      <th>CusType</th>\n",
       "      <th>original_cfr</th>\n",
       "      <th>adjusted_cfr_s1</th>\n",
       "      <th>adjusted_cfr_s2</th>\n",
       "      <th>adjusted_cfr_s3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>CRS</td>\n",
       "      <td>99.708370</td>\n",
       "      <td>99.708370</td>\n",
       "      <td>99.708370</td>\n",
       "      <td>99.708370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>KA</td>\n",
       "      <td>99.226985</td>\n",
       "      <td>99.226985</td>\n",
       "      <td>99.226985</td>\n",
       "      <td>99.226985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shortage</td>\n",
       "      <td>CRS</td>\n",
       "      <td>90.274161</td>\n",
       "      <td>92.049987</td>\n",
       "      <td>91.525138</td>\n",
       "      <td>91.104408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shortage</td>\n",
       "      <td>KA</td>\n",
       "      <td>80.208761</td>\n",
       "      <td>83.422698</td>\n",
       "      <td>83.422698</td>\n",
       "      <td>83.422698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shortage CusType  original_cfr  adjusted_cfr_s1  adjusted_cfr_s2  \\\n",
       "0    normal     CRS     99.708370        99.708370        99.708370   \n",
       "1    normal      KA     99.226985        99.226985        99.226985   \n",
       "2  shortage     CRS     90.274161        92.049987        91.525138   \n",
       "3  shortage      KA     80.208761        83.422698        83.422698   \n",
       "\n",
       "   adjusted_cfr_s3  \n",
       "0        99.708370  \n",
       "1        99.226985  \n",
       "2        91.104408  \n",
       "3        83.422698  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cfr = df1[['order_type','pgi_type','shortage','CusType','Order Qty','ConfirmQty','adjusted_order_qty_s1','adjusted_order_qty_s2','adjusted_order_qty_s3','adjusted_confirm_qty_s1','adjusted_confirm_qty_s2','adjusted_confirm_qty_s3']]\n",
    "\n",
    "df_cfr_groupby_shortage = df_cfr.groupby(['shortage','CusType']).sum().reset_index()\n",
    "\n",
    "df_cfr_groupby_shortage['original_cfr'] = df_cfr_groupby_shortage['ConfirmQty']/df_cfr_groupby_shortage['Order Qty']*100\n",
    "df_cfr_groupby_shortage['adjusted_cfr_s1'] = df_cfr_groupby_shortage['adjusted_confirm_qty_s1']/df_cfr_groupby_shortage['adjusted_order_qty_s1']*100\n",
    "df_cfr_groupby_shortage['adjusted_cfr_s2'] = df_cfr_groupby_shortage['adjusted_confirm_qty_s2']/df_cfr_groupby_shortage['adjusted_order_qty_s2']*100\n",
    "df_cfr_groupby_shortage['adjusted_cfr_s3'] = df_cfr_groupby_shortage['adjusted_confirm_qty_s3']/df_cfr_groupby_shortage['adjusted_order_qty_s3']*100\n",
    "\n",
    "cfr = df_cfr_groupby_shortage[['shortage','CusType','original_cfr','adjusted_cfr_s1','adjusted_cfr_s2','adjusted_cfr_s3']]\n",
    "cfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sales \n",
    "#### CRS by allocation_value* index , KA by allocation_value * CFR% improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drive_sale_s1    54707003\n",
       "drive_sale_s2    54722451\n",
       "drive_sale_s3    53473356\n",
       "dtype: int32"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_sale_s1 = []\n",
    "drive_sale_s2 = []\n",
    "drive_sale_s3 = []\n",
    "\n",
    "s1_index = 0.25\n",
    "s2_index = 0.5\n",
    "s3_index = 1\n",
    "ka_index = 1 # (cfr[ (cfr['shortage']=='shortage') & (cfr['CusType']=='KA')].adjusted_cfr_s1  -cfr[ (cfr['shortage']=='shortage') & (cfr['CusType']=='KA')].original_cfr)/100\n",
    "\n",
    "for ot,pt,stg,cus, gv1,gv2,gv3 in zip(df1['order_type'],df1['pgi_type'],df1['shortage'],df1['CusType'],\n",
    "                                        df1['gap_can_be_fill_value_s1'],df1['gap_can_be_fill_value_s2'],df1['gap_can_be_fill_value_s3']):\n",
    "        \n",
    "        if stg == 'shortage' and pt != 'exceed'and cus =='CRS':\n",
    "            drive_sale_s1.append(s1_index*gv1)\n",
    "            drive_sale_s2.append(s2_index*gv2)\n",
    "            drive_sale_s3.append(s3_index*gv3)  \n",
    "            \n",
    "        elif stg == 'shortage' and cus =='KA':\n",
    "            drive_sale_s1.append(ka_index*gv1)\n",
    "            drive_sale_s2.append(ka_index*gv2)\n",
    "            drive_sale_s3.append(ka_index*gv3)\n",
    "            \n",
    "        else: \n",
    "            drive_sale_s1.append(None)\n",
    "            drive_sale_s2.append(None)\n",
    "            drive_sale_s3.append(None)\n",
    "            \n",
    "df1['drive_sale_s1']=drive_sale_s1\n",
    "df1['drive_sale_s2']=drive_sale_s2\n",
    "df1['drive_sale_s3']=drive_sale_s3\n",
    "df1[['drive_sale_s1','drive_sale_s2','drive_sale_s3']].sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\the7490\\Downloads\\crs_processed_shortage_crs+kasap_94_transit_1.8_ka_excl_61_tag_incl61_exceed_back.csv',encoding='utf-8',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmove = pd.read_csv(r'C:\\Users\\the7490\\Downloads\\price_movement_update.csv')\n",
    "pmove['date'] = pd.to_datetime(pmove['date'])\n",
    "pmove['week'] = pmove['date'].apply(lambda x: x.strftime(\"%W\")).astype(int) # Start from Monday\n",
    "pmove[['sold_to_pt','material']] = pmove[['sold_to_pt','material']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.merge(df1, pmove[['year','week','sold_to_pt','material','net_price','price_movement']], on =['year','week','sold_to_pt','material'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1587988, 65)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2[df2['Order Qty']>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv(r'C:\\Users\\the7490\\Downloads\\crs_processed_ka_sellout_price_18_ov.csv',encoding='utf-8',index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRS', 'KA'], dtype=object)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['CusType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material</th>\n",
       "      <th>Net price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89688</th>\n",
       "      <td>961400</td>\n",
       "      <td>315.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107724</th>\n",
       "      <td>961400</td>\n",
       "      <td>251.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143315</th>\n",
       "      <td>961400</td>\n",
       "      <td>315.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164218</th>\n",
       "      <td>961400</td>\n",
       "      <td>251.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167867</th>\n",
       "      <td>961400</td>\n",
       "      <td>235.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133213</th>\n",
       "      <td>961400</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142682</th>\n",
       "      <td>961400</td>\n",
       "      <td>313.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220244</th>\n",
       "      <td>961400</td>\n",
       "      <td>313.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263771</th>\n",
       "      <td>961400</td>\n",
       "      <td>266.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274301</th>\n",
       "      <td>961400</td>\n",
       "      <td>285.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Material  Net price\n",
       "89688    961400     315.41\n",
       "107724   961400     251.07\n",
       "143315   961400     315.41\n",
       "164218   961400     251.07\n",
       "167867   961400     235.37\n",
       "...         ...        ...\n",
       "133213   961400       0.00\n",
       "142682   961400     313.83\n",
       "220244   961400     313.83\n",
       "263771   961400     266.76\n",
       "274301   961400     285.59\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va[va['Material']==961400][['Material','Net price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_price_list.to_csv(r'C:\\Users\\the7490\\Downloads\\sku_price_list.csv',encoding='utf-8',index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18 = pd.read_csv(r'C:\\Users\\the7490\\Downloads\\crs_processed_ka_sellout_price_1.8_utf.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sold_to_pt', 'material', 'Doc. Date', 'Order Qty', 'ConfirmQty',\n",
       "       'count', 'Name 1', 'Plnt', 'Description', 'year', 'week', 'ds',\n",
       "       'basic_code', 'order_qty', 'pgi_qty', 'suggest_box', 'sale_box_week1',\n",
       "       'sale_box_week2', 'sale_box_week3', 'sale_box_week4', 'sale_box_week5',\n",
       "       'avg_sales_box_day', 'avail_inventory_box', 'intrans_inventory_box',\n",
       "       'avaliable_days', 'sale_week', 'sale_week1', 'sale_week2', 'sale_week3',\n",
       "       'sale_week4', 'Category', 'CategoryName', 'MaxDays', 'MinDays',\n",
       "       'sale_month', 'shortage', 'order_type', 'pgi_type', 'CusType',\n",
       "       'exceed_pgi_box', 'gap_box_s1', 'gap_box_s2', 'gap_box_s3', 'Net price',\n",
       "       'gap_fill_index_s1', 'gap_fill_index_s2', 'gap_fill_index_s3',\n",
       "       'gap_box_can_be_fill_s1', 'gap_box_can_be_fill_s2',\n",
       "       'gap_box_can_be_fill_s3', 'gap_can_be_fill_value_s1',\n",
       "       'gap_can_be_fill_value_s2', 'gap_can_be_fill_value_s3',\n",
       "       'exceed_fill_index_s1', 'exceed_fill_index_s2', 'exceed_fill_index_s3',\n",
       "       'adjusted_order_qty', 'adjusted_confirm_qty_s1',\n",
       "       'adjusted_confirm_qty_s2', 'adjusted_confirm_qty_s3', 'drive_sale_s1',\n",
       "       'drive_sale_s2', 'drive_sale_s3', 'net_price', 'price_movement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = df18[['sold_to_pt', 'material', 'Order Qty', 'ConfirmQty','year', 'week','adjusted_order_qty', 'adjusted_confirm_qty_s1',\n",
    "       'adjusted_confirm_qty_s2', 'adjusted_confirm_qty_s3', 'drive_sale_s1',\n",
    "       'drive_sale_s2', 'drive_sale_s3','gap_box_s1', 'gap_box_s2', 'gap_box_s3','Net price', 'gap_box_can_be_fill_s1', 'gap_box_can_be_fill_s2',\n",
    "       'gap_box_can_be_fill_s3','gap_can_be_fill_value_s1',\n",
    "       'gap_can_be_fill_value_s2', 'gap_can_be_fill_value_s3']]\n",
    "op['order_value'] = op['Order Qty']*op['Net price']\n",
    "op = op.groupby(['sold_to_pt', 'material','year','week']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sold_to_pt</th>\n",
       "      <th>material</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>Order Qty</th>\n",
       "      <th>ConfirmQty</th>\n",
       "      <th>adjusted_order_qty</th>\n",
       "      <th>adjusted_confirm_qty_s1</th>\n",
       "      <th>adjusted_confirm_qty_s2</th>\n",
       "      <th>adjusted_confirm_qty_s3</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_box_s1</th>\n",
       "      <th>gap_box_s2</th>\n",
       "      <th>gap_box_s3</th>\n",
       "      <th>gap_box_can_be_fill_s1</th>\n",
       "      <th>gap_box_can_be_fill_s2</th>\n",
       "      <th>gap_box_can_be_fill_s3</th>\n",
       "      <th>gap_can_be_fill_value_s1</th>\n",
       "      <th>gap_can_be_fill_value_s2</th>\n",
       "      <th>gap_can_be_fill_value_s3</th>\n",
       "      <th>order_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6700005</td>\n",
       "      <td>113944</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.116945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6700005</td>\n",
       "      <td>763982</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.059526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6700005</td>\n",
       "      <td>4260705</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4569.788461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6700006</td>\n",
       "      <td>113714</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1923.679393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6700006</td>\n",
       "      <td>113714</td>\n",
       "      <td>2020</td>\n",
       "      <td>41</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3847.358786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262858</th>\n",
       "      <td>7126181</td>\n",
       "      <td>4270317</td>\n",
       "      <td>2021</td>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>529.595995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262859</th>\n",
       "      <td>7126181</td>\n",
       "      <td>4272720</td>\n",
       "      <td>2021</td>\n",
       "      <td>43</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.080055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262860</th>\n",
       "      <td>7126181</td>\n",
       "      <td>4273105</td>\n",
       "      <td>2021</td>\n",
       "      <td>43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1762.157435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262861</th>\n",
       "      <td>7126181</td>\n",
       "      <td>4274870</td>\n",
       "      <td>2021</td>\n",
       "      <td>43</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987.409506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262862</th>\n",
       "      <td>7126181</td>\n",
       "      <td>4276461</td>\n",
       "      <td>2021</td>\n",
       "      <td>43</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2782.398232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262863 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sold_to_pt  material  year  week  Order Qty  ConfirmQty  \\\n",
       "0           6700005    113944  2021     9        1.0         1.0   \n",
       "1           6700005    763982  2021     9        1.0         1.0   \n",
       "2           6700005   4260705  2021     9       39.0        39.0   \n",
       "3           6700006    113714  2020    40       20.0         0.0   \n",
       "4           6700006    113714  2020    41       40.0        20.0   \n",
       "...             ...       ...   ...   ...        ...         ...   \n",
       "1262858     7126181   4270317  2021    43        3.0         3.0   \n",
       "1262859     7126181   4272720  2021    43       15.0        15.0   \n",
       "1262860     7126181   4273105  2021    43       10.0        10.0   \n",
       "1262861     7126181   4274870  2021    43       15.0        15.0   \n",
       "1262862     7126181   4276461  2021    43       21.0        21.0   \n",
       "\n",
       "         adjusted_order_qty  adjusted_confirm_qty_s1  adjusted_confirm_qty_s2  \\\n",
       "0                       1.0                      1.0                      1.0   \n",
       "1                       1.0                      1.0                      1.0   \n",
       "2                      39.0                     39.0                     39.0   \n",
       "3                      20.0                      0.0                      0.0   \n",
       "4                      40.0                     20.0                     20.0   \n",
       "...                     ...                      ...                      ...   \n",
       "1262858                 3.0                      3.0                      3.0   \n",
       "1262859                15.0                     15.0                     15.0   \n",
       "1262860                10.0                     10.0                     10.0   \n",
       "1262861                15.0                     15.0                     15.0   \n",
       "1262862                21.0                     21.0                     21.0   \n",
       "\n",
       "         adjusted_confirm_qty_s3  ...  gap_box_s1  gap_box_s2  gap_box_s3  \\\n",
       "0                            1.0  ...         0.0         0.0         0.0   \n",
       "1                            1.0  ...         0.0         0.0         0.0   \n",
       "2                           39.0  ...         0.0         0.0         0.0   \n",
       "3                            0.0  ...         0.0         0.0         0.0   \n",
       "4                           20.0  ...         0.0         0.0         0.0   \n",
       "...                          ...  ...         ...         ...         ...   \n",
       "1262858                      3.0  ...         0.0         0.0         0.0   \n",
       "1262859                     15.0  ...         0.0         0.0         0.0   \n",
       "1262860                     10.0  ...         0.0         0.0         0.0   \n",
       "1262861                     15.0  ...         0.0         0.0         0.0   \n",
       "1262862                     21.0  ...         0.0         0.0         0.0   \n",
       "\n",
       "         gap_box_can_be_fill_s1  gap_box_can_be_fill_s2  \\\n",
       "0                           0.0                     0.0   \n",
       "1                           0.0                     0.0   \n",
       "2                           0.0                     0.0   \n",
       "3                           0.0                     0.0   \n",
       "4                           0.0                     0.0   \n",
       "...                         ...                     ...   \n",
       "1262858                     0.0                     0.0   \n",
       "1262859                     0.0                     0.0   \n",
       "1262860                     0.0                     0.0   \n",
       "1262861                     0.0                     0.0   \n",
       "1262862                     0.0                     0.0   \n",
       "\n",
       "         gap_box_can_be_fill_s3  gap_can_be_fill_value_s1  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "1262858                     0.0                       0.0   \n",
       "1262859                     0.0                       0.0   \n",
       "1262860                     0.0                       0.0   \n",
       "1262861                     0.0                       0.0   \n",
       "1262862                     0.0                       0.0   \n",
       "\n",
       "         gap_can_be_fill_value_s2  gap_can_be_fill_value_s3  order_value  \n",
       "0                             0.0                       0.0    94.116945  \n",
       "1                             0.0                       0.0    53.059526  \n",
       "2                             0.0                       0.0  4569.788461  \n",
       "3                             0.0                       0.0  1923.679393  \n",
       "4                             0.0                       0.0  3847.358786  \n",
       "...                           ...                       ...          ...  \n",
       "1262858                       0.0                       0.0   529.595995  \n",
       "1262859                       0.0                       0.0  2648.080055  \n",
       "1262860                       0.0                       0.0  1762.157435  \n",
       "1262861                       0.0                       0.0  1987.409506  \n",
       "1262862                       0.0                       0.0  2782.398232  \n",
       "\n",
       "[1262863 rows x 23 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = op.drop(columns = ['Net price'])\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellout = pd.read_csv(r'C:\\Users\\the7490\\MDLZ\\Central Analytics Team CAT - Projects\\Beta Quadrant\\KUNLUN\\01.Raw Data\\M1_0_0-0_TableSink1-0-.tsv', sep='\\t',header =None)\n",
    "sellout.columns = ['year','week','sold_to_pt','material','sale_week','Amount1','Amount2']\n",
    "\n",
    "# drop unwanted columns\n",
    "sellout = sellout.drop(columns = ['Amount1','Amount2'])\n",
    "\n",
    "# Turn week into int\n",
    "sellout['week'] = sellout.week.str[1:].astype(int)\n",
    "sellout[['sold_to_pt','material']] = sellout[['sold_to_pt','material']].astype(str)\n",
    "\n",
    "# 为了和处理数据匹配week = week-1\n",
    "sellout['week'] = sellout['week'] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "custype = df18[['sold_to_pt','CusType']].drop_duplicates().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "op[['sold_to_pt','material']] = op[['sold_to_pt','material']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.merge(op, sellout, on=['year','week','sold_to_pt','material'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.merge(output, custype, on=['sold_to_pt'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sold_to_pt</th>\n",
       "      <th>material</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>Order Qty</th>\n",
       "      <th>ConfirmQty</th>\n",
       "      <th>adjusted_order_qty</th>\n",
       "      <th>adjusted_confirm_qty_s1</th>\n",
       "      <th>adjusted_confirm_qty_s2</th>\n",
       "      <th>adjusted_confirm_qty_s3</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_box_s3</th>\n",
       "      <th>gap_box_can_be_fill_s1</th>\n",
       "      <th>gap_box_can_be_fill_s2</th>\n",
       "      <th>gap_box_can_be_fill_s3</th>\n",
       "      <th>gap_can_be_fill_value_s1</th>\n",
       "      <th>gap_can_be_fill_value_s2</th>\n",
       "      <th>gap_can_be_fill_value_s3</th>\n",
       "      <th>order_value</th>\n",
       "      <th>sale_week</th>\n",
       "      <th>CusType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6700005</td>\n",
       "      <td>113944</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.116945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6700005</td>\n",
       "      <td>763982</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.059526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6700005</td>\n",
       "      <td>4260705</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4569.788461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6700006</td>\n",
       "      <td>113714</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1923.679393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6700006</td>\n",
       "      <td>113714</td>\n",
       "      <td>2020</td>\n",
       "      <td>41</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3847.358786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sold_to_pt material  year  week  Order Qty  ConfirmQty  adjusted_order_qty  \\\n",
       "0    6700005   113944  2021     9        1.0         1.0                 1.0   \n",
       "1    6700005   763982  2021     9        1.0         1.0                 1.0   \n",
       "2    6700005  4260705  2021     9       39.0        39.0                39.0   \n",
       "3    6700006   113714  2020    40       20.0         0.0                20.0   \n",
       "4    6700006   113714  2020    41       40.0        20.0                40.0   \n",
       "\n",
       "   adjusted_confirm_qty_s1  adjusted_confirm_qty_s2  adjusted_confirm_qty_s3  \\\n",
       "0                      1.0                      1.0                      1.0   \n",
       "1                      1.0                      1.0                      1.0   \n",
       "2                     39.0                     39.0                     39.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                     20.0                     20.0                     20.0   \n",
       "\n",
       "   ...  gap_box_s3  gap_box_can_be_fill_s1  gap_box_can_be_fill_s2  \\\n",
       "0  ...         0.0                     0.0                     0.0   \n",
       "1  ...         0.0                     0.0                     0.0   \n",
       "2  ...         0.0                     0.0                     0.0   \n",
       "3  ...         0.0                     0.0                     0.0   \n",
       "4  ...         0.0                     0.0                     0.0   \n",
       "\n",
       "   gap_box_can_be_fill_s3  gap_can_be_fill_value_s1  gap_can_be_fill_value_s2  \\\n",
       "0                     0.0                       0.0                       0.0   \n",
       "1                     0.0                       0.0                       0.0   \n",
       "2                     0.0                       0.0                       0.0   \n",
       "3                     0.0                       0.0                       0.0   \n",
       "4                     0.0                       0.0                       0.0   \n",
       "\n",
       "   gap_can_be_fill_value_s3  order_value  sale_week  CusType  \n",
       "0                       0.0    94.116945        NaN       KA  \n",
       "1                       0.0    53.059526        NaN       KA  \n",
       "2                       0.0  4569.788461        NaN       KA  \n",
       "3                       0.0  1923.679393        NaN       KA  \n",
       "4                       0.0  3847.358786        NaN       KA  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12351815.401646996"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r'C:\\Users\\the7490\\Downloads\\output_18boundary_price_match.csv',encoding='utf-8',index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[['sold_to_pt','material']] = new[['sold_to_pt','material']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4337a19fdc842dfb36504875733a19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output1 = pd.merge(op, new, on=['year','week','sold_to_pt','material'],how='outer')\n",
    "result_show(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28468057.633277006"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12351815.401647002"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12351815.401646998"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop_duplicates(['year','week','sold_to_pt','material'])['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43388332146723857"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['sale_week'].sum()/sellout['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_csv(r'C:\\Users\\the7490\\Downloads\\sellout_by_week_following_updated.csv',header =None)\n",
    "new.columns = ['sold_to_pt','material','year','week','sale_week','sale_week1','sale_week2','sale_week3','sale_week4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28468057.63327701"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sold_to_pt      int64\n",
       "material        int64\n",
       "year            int64\n",
       "week            int64\n",
       "sale_week     float64\n",
       "sale_week1    float64\n",
       "sale_week2    float64\n",
       "sale_week3    float64\n",
       "sale_week4    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "op[['sold_to_pt','material']] = op[['sold_to_pt','material']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12351815.401646996"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(op, new, on=['year','week','sold_to_pt','material'],how='left')\n",
    "test['sale_week'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115375b9539f43d68cefe228bce0d5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_show(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['Order Qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78288200"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crs['order_qty'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer SKU连续下单没供足周数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# year_week_m = pd.DataFrame()\n",
    "# material_list = []\n",
    "# year_list = []\n",
    "# week_list = []\n",
    "# num_list = []\n",
    "# num =0\n",
    "\n",
    "# for sku in df1['material'].unique():\n",
    "#     if sku=='NaN':\n",
    "#         continue\n",
    "#     else:\n",
    "#         for year in ['2020','2021']:\n",
    "#             for week in df1['week'].sort_values().unique():\n",
    "#                 year_list.append(year)\n",
    "#                 week_list.append(week)\n",
    "#                 material_list.append(sku)\n",
    "#                 num_list.append(num)\n",
    "#                 num+=1\n",
    "        \n",
    "# year_week_m['year'] = year_list\n",
    "# year_week_m['week'] = week_list\n",
    "# year_week_m['material'] = material_list\n",
    "# year_week_m['num'] = num_list\n",
    "\n",
    "# result_show(year_week_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crs_list = df1[df1['CusType']=='CRS'].sold_to_pt.unique()\n",
    "\n",
    "# cus_sku_list = []\n",
    "\n",
    "# for cus in crs_list:\n",
    "#     temp_cus_sku = df1[(df1['sold_to_pt']==str(cus))][['Order Qty','ConfirmQty','year','week','material','sold_to_pt']].groupby(['year','week','material','sold_to_pt']).sum().reset_index()\n",
    "#     temp = pd.merge(year_week_m,temp_cus_sku,on = ['year','week','material'],how='left')\n",
    "#     temp['sold_to_pt'] = str(cus)\n",
    "#     cus_sku_list.append(temp)\n",
    "    \n",
    "# dfs = pd.concat(cus_sku_list) #每个cus每个sku补全week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By cus by sku calculate shortage\n",
    "cus_sku_df = df1[['Order Qty','ConfirmQty','year','week','material','sold_to_pt']].groupby(['sold_to_pt','material','year','week']).sum().reset_index()\n",
    "\n",
    "# Order < confirm → shortage 1 else normal 0\n",
    "cus_sku_df['shortage_cus'] = cus_sku_df[['Order Qty','ConfirmQty']].apply(lambda x: 1 if x['ConfirmQty']<x['Order Qty'] else 0, axis = 1).astype(int)\n",
    "cus_sku_df = cus_sku_df.sort_values(['sold_to_pt','material','year','week'])\n",
    "\n",
    "cus_sku_df['num'] = cus_sku_df['year']*100+cus_sku_df['week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23a512a57db45f586ad01d8c72955c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_show(cus_sku_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sold_to_pt    object\n",
       "material      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get customer sku list\n",
    "crs_sku = df1[['sold_to_pt','material']].drop_duplicates()\n",
    "crs_sku.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=cus_sku_df[(cus_sku_df['material']==str(113714))& (cus_sku_df['sold_to_pt']==str(6700006))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ed17e4c23a46fdb499d921ba0fa6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def row_number(df, groupby_col=[], orderby_col='', ascending=True):\n",
    "    return df.groupby(groupby_col)[orderby_col].rank(ascending=True)\n",
    "\n",
    "# Tag shortage weeknum \n",
    "tag_weeknum = []\n",
    "# dfs = dfs[~dfs['material'].isna()]\n",
    "\n",
    "for cus, sku in zip(crs_sku['sold_to_pt'],crs_sku['material']):\n",
    "\n",
    "    t = cus_sku_df[(cus_sku_df['material']==sku)& (cus_sku_df['sold_to_pt']==cus)].rename(columns = {'shortage_cus':'stg'})\n",
    "    t['row1'] = row_number(t, groupby_col=['material','stg'], orderby_col='num', ascending=True) # row_number over material and stg\n",
    "    t['row2'] = t['num'].rank(ascending =True)\n",
    "    t['row1'] = t[['row1','stg']].apply(lambda x: x['row1'] if x['stg'] ==1 else None, axis=1)\n",
    "    t['diff'] = t['row2']-t['row1'] # same diff value means continuous stg\n",
    "\n",
    "    t1 = t.groupby(['material','diff']).agg({'row1':'count'}).reset_index().rename(columns={'row1':'count'}).sort_values('diff')\n",
    "    t1['count_cum'] = t1['count'].cumsum(axis=0) # assit value to calculate continuous stg week starting from 1\n",
    "\n",
    "    dft = pd.merge(t,t1, on=['material','diff'],how='left')\n",
    "    dft['stg_con'] = dft['row1'] - dft['count_cum'] + dft['count']\n",
    "    \n",
    "    tag_weeknum.append(dft)\n",
    "\n",
    "    \n",
    "cus_sku_stg = pd.concat(tag_weeknum)\n",
    "result_show(cus_sku_stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########先导出!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_sku_stg.to_csv(r'C:\\Users\\the7490\\Downloads\\stg_con.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge back to main table\n",
    "df3 = pd.merge(df2,cus_sku_stg[['year','week','sold_to_pt','material','stg_con']],on= ['year','week','material','sold_to_pt'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc. Date</th>\n",
       "      <th>Order Qty</th>\n",
       "      <th>ConfirmQty</th>\n",
       "      <th>count</th>\n",
       "      <th>Name 1</th>\n",
       "      <th>Plnt</th>\n",
       "      <th>Description</th>\n",
       "      <th>Net price</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>adjusted_order_qty</th>\n",
       "      <th>adjusted_confirm_qty_s1</th>\n",
       "      <th>adjusted_confirm_qty_s2</th>\n",
       "      <th>adjusted_confirm_qty_s3</th>\n",
       "      <th>drive_sale_s1</th>\n",
       "      <th>drive_sale_s2</th>\n",
       "      <th>drive_sale_s3</th>\n",
       "      <th>net_price</th>\n",
       "      <th>price_movement</th>\n",
       "      <th>stg_con</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>邢台市吉星商贸有限公司</td>\n",
       "      <td>CN81</td>\n",
       "      <td>乐之薄片-100克X24-原味-单卷装</td>\n",
       "      <td>66.74</td>\n",
       "      <td>2021</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>邢台市吉星商贸有限公司</td>\n",
       "      <td>CN81</td>\n",
       "      <td>乐之薄片-100克X24-原味-单卷装</td>\n",
       "      <td>66.74</td>\n",
       "      <td>2021</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>邢台市吉星商贸有限公司</td>\n",
       "      <td>CN81</td>\n",
       "      <td>太平梳打400克X12加铁奶盐</td>\n",
       "      <td>99.17</td>\n",
       "      <td>2020</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>邢台市吉星商贸有限公司</td>\n",
       "      <td>CN81</td>\n",
       "      <td>太平梳打400克X12加铁奶盐</td>\n",
       "      <td>99.17</td>\n",
       "      <td>2020</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>邢台市吉星商贸有限公司</td>\n",
       "      <td>CN81</td>\n",
       "      <td>太平梳打400克X12加铁奶盐</td>\n",
       "      <td>99.17</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc. Date  Order Qty  ConfirmQty  count       Name 1  Plnt  \\\n",
       "0 2021-04-02       10.0        10.0      1  邢台市吉星商贸有限公司  CN81   \n",
       "1 2021-09-02        2.0         2.0      1  邢台市吉星商贸有限公司  CN81   \n",
       "2 2020-10-29        5.0         5.0      1  邢台市吉星商贸有限公司  CN81   \n",
       "3 2020-11-27        5.0         5.0      1  邢台市吉星商贸有限公司  CN81   \n",
       "4 2020-12-25        5.0         5.0      1  邢台市吉星商贸有限公司  CN81   \n",
       "\n",
       "           Description  Net price  year  week  ... adjusted_order_qty  \\\n",
       "0  乐之薄片-100克X24-原味-单卷装      66.74  2021    13  ...               10.0   \n",
       "1  乐之薄片-100克X24-原味-单卷装      66.74  2021    35  ...                2.0   \n",
       "2      太平梳打400克X12加铁奶盐      99.17  2020    43  ...                5.0   \n",
       "3      太平梳打400克X12加铁奶盐      99.17  2020    47  ...                5.0   \n",
       "4      太平梳打400克X12加铁奶盐      99.17  2020    51  ...                5.0   \n",
       "\n",
       "  adjusted_confirm_qty_s1 adjusted_confirm_qty_s2 adjusted_confirm_qty_s3  \\\n",
       "0                    10.0                    10.0                    10.0   \n",
       "1                     2.0                     2.0                     2.0   \n",
       "2                     5.0                     5.0                     5.0   \n",
       "3                     5.0                     5.0                     5.0   \n",
       "4                     5.0                     5.0                     5.0   \n",
       "\n",
       "   drive_sale_s1  drive_sale_s2  drive_sale_s3  net_price  price_movement  \\\n",
       "0            NaN            NaN            NaN        NaN             NaN   \n",
       "1            NaN            NaN            NaN        NaN             NaN   \n",
       "2            NaN            NaN            NaN        NaN             NaN   \n",
       "3            NaN            NaN            NaN        NaN             NaN   \n",
       "4            NaN            NaN            NaN        NaN             NaN   \n",
       "\n",
       "   stg_con  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(r'C:\\Users\\the7490\\Downloads\\crs_processed_ka_sellout_stgcon_updated_gbk.csv',encoding='gbk',index =None,date_format=\"%Y/%m/%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1946265584574830874e6b5a31c89ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sellout = pd.read_csv(r'C:\\Users\\the7490\\MDLZ\\Central Analytics Team CAT - Projects\\Beta Quadrant\\KUNLUN\\01.Raw Data\\M1_0_0-0_TableSink1-0-.tsv', sep='\\t',header =None)\n",
    "sellout.columns = ['year','week','sold_to_pt','material','sale_week','Amount1','Amount2']\n",
    "\n",
    "# drop unwanted columns\n",
    "sellout = sellout.drop(columns = ['Amount1','Amount2'])\n",
    "\n",
    "# Turn week into int\n",
    "sellout['week'] = sellout.week.str[1:].astype(int)\n",
    "sellout[['sold_to_pt','material']] = sellout[['sold_to_pt','material']].astype(str)\n",
    "\n",
    "# 为了和处理数据匹配week = week-1\n",
    "sellout['week'] = sellout['week'] -1\n",
    "\n",
    "result_show(sellout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sold_to_pt</th>\n",
       "      <th>material</th>\n",
       "      <th>sale_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>39</td>\n",
       "      <td>6701474</td>\n",
       "      <td>244336</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>39</td>\n",
       "      <td>6701474</td>\n",
       "      <td>244344</td>\n",
       "      <td>0.166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>39</td>\n",
       "      <td>6701474</td>\n",
       "      <td>357405</td>\n",
       "      <td>1.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>39</td>\n",
       "      <td>6701474</td>\n",
       "      <td>357407</td>\n",
       "      <td>-0.916666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>39</td>\n",
       "      <td>6701474</td>\n",
       "      <td>4009396</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130401</th>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>7124651</td>\n",
       "      <td>847473</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130402</th>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>7124651</td>\n",
       "      <td>969585</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130403</th>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>7124651</td>\n",
       "      <td>974347</td>\n",
       "      <td>0.166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130404</th>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>7124651</td>\n",
       "      <td>974352</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130405</th>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>7124651</td>\n",
       "      <td>974356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130406 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  week sold_to_pt material  sale_week\n",
       "0        2020    39    6701474   244336   0.083333\n",
       "1        2020    39    6701474   244344   0.166666\n",
       "2        2020    39    6701474   357405   1.041667\n",
       "3        2020    39    6701474   357407  -0.916666\n",
       "4        2020    39    6701474  4009396   3.250000\n",
       "...       ...   ...        ...      ...        ...\n",
       "2130401  2021    52    7124651   847473   0.250000\n",
       "2130402  2021    52    7124651   969585   1.750000\n",
       "2130403  2021    52    7124651   974347   0.166666\n",
       "2130404  2021    52    7124651   974352   2.750000\n",
       "2130405  2021    52    7124651   974356   1.000000\n",
       "\n",
       "[2130406 rows x 5 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GROUP BY WEEK\n",
    "sellout_week = sellout.groupby(['year','week','sold_to_pt','material']).agg({'sale_week':'sum'}).reset_index()\n",
    "sellout_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sold_to_pt</th>\n",
       "      <th>material</th>\n",
       "      <th>Order Qty</th>\n",
       "      <th>ConfirmQty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244090</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244156</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244336</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>357405</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>357407</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759135</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061003</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759136</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061348</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759137</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061491</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759138</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4262057</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759139</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>610123</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759140 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  week sold_to_pt material  Order Qty  ConfirmQty\n",
       "0       2020    40    6701520   244090       40.0        40.0\n",
       "1       2020    40    6701520   244156       40.0        40.0\n",
       "2       2020    40    6701520   244336        5.0         5.0\n",
       "3       2020    40    6701520   357405       20.0        20.0\n",
       "4       2020    40    6701520   357407       20.0        20.0\n",
       "...      ...   ...        ...      ...        ...         ...\n",
       "759135  2021    41    7118864  4061003       15.0        15.0\n",
       "759136  2021    41    7118864  4061348       10.0        10.0\n",
       "759137  2021    41    7118864  4061491        5.0         5.0\n",
       "759138  2021    41    7118864  4262057       12.0        12.0\n",
       "759139  2021    41    7118864   610123       15.0        15.0\n",
       "\n",
       "[759140 rows x 6 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellin_week = df1[df1['CusType']=='CRS'].groupby(['year','week','sold_to_pt','material']).agg({'Order Qty':'sum','ConfirmQty':'sum'}).reset_index()\n",
    "sellin_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sold_to_pt</th>\n",
       "      <th>material</th>\n",
       "      <th>Order Qty</th>\n",
       "      <th>ConfirmQty</th>\n",
       "      <th>sale_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244090</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.333332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244156</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.916666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244336</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>357405</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>357407</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759135</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061003</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.916659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759136</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061348</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.124995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759137</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061491</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759138</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4262057</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759139</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>610123</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.999994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759140 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  week sold_to_pt material  Order Qty  ConfirmQty  sale_week\n",
       "0       2020    40    6701520   244090       40.0        40.0  39.333332\n",
       "1       2020    40    6701520   244156       40.0        40.0  36.916666\n",
       "2       2020    40    6701520   244336        5.0         5.0        NaN\n",
       "3       2020    40    6701520   357405       20.0        20.0  23.999999\n",
       "4       2020    40    6701520   357407       20.0        20.0  22.999999\n",
       "...      ...   ...        ...      ...        ...         ...        ...\n",
       "759135  2021    41    7118864  4061003       15.0        15.0  14.916659\n",
       "759136  2021    41    7118864  4061348       10.0        10.0  13.124995\n",
       "759137  2021    41    7118864  4061491        5.0         5.0        NaN\n",
       "759138  2021    41    7118864  4262057       12.0        12.0   0.375000\n",
       "759139  2021    41    7118864   610123       15.0        15.0  13.999994\n",
       "\n",
       "[759140 rows x 7 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellinout = pd.merge(sellin_week, sellout_week,on=['year','week','sold_to_pt','material'],how='left')\n",
    "sellinout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_ka_sku = va_ka_sku.rename(columns = {'Material':'material'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['material', 'Description', 'Net price'], dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_ka_sku.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellinout = pd.merge(sellinout, va_ka_sku[['material','Net price']], on='material',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>sold_to_pt</th>\n",
       "      <th>material</th>\n",
       "      <th>Order Qty</th>\n",
       "      <th>ConfirmQty</th>\n",
       "      <th>sale_week</th>\n",
       "      <th>Net price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244090</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.333332</td>\n",
       "      <td>70.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244156</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.916666</td>\n",
       "      <td>67.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>244336</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>357405</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.999999</td>\n",
       "      <td>70.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>6701520</td>\n",
       "      <td>357407</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.999999</td>\n",
       "      <td>70.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759135</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061003</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.916659</td>\n",
       "      <td>331.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759136</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061348</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.124995</td>\n",
       "      <td>331.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759137</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4061491</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759138</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>4262057</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>193.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759139</th>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>7118864</td>\n",
       "      <td>610123</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.999994</td>\n",
       "      <td>331.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759140 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  week sold_to_pt material  Order Qty  ConfirmQty  sale_week  \\\n",
       "0       2020    40    6701520   244090       40.0        40.0  39.333332   \n",
       "1       2020    40    6701520   244156       40.0        40.0  36.916666   \n",
       "2       2020    40    6701520   244336        5.0         5.0        NaN   \n",
       "3       2020    40    6701520   357405       20.0        20.0  23.999999   \n",
       "4       2020    40    6701520   357407       20.0        20.0  22.999999   \n",
       "...      ...   ...        ...      ...        ...         ...        ...   \n",
       "759135  2021    41    7118864  4061003       15.0        15.0  14.916659   \n",
       "759136  2021    41    7118864  4061348       10.0        10.0  13.124995   \n",
       "759137  2021    41    7118864  4061491        5.0         5.0        NaN   \n",
       "759138  2021    41    7118864  4262057       12.0        12.0   0.375000   \n",
       "759139  2021    41    7118864   610123       15.0        15.0  13.999994   \n",
       "\n",
       "        Net price  \n",
       "0           70.01  \n",
       "1           67.04  \n",
       "2           88.09  \n",
       "3           70.58  \n",
       "4           70.58  \n",
       "...           ...  \n",
       "759135     331.53  \n",
       "759136     331.53  \n",
       "759137     331.53  \n",
       "759138     193.58  \n",
       "759139     331.53  \n",
       "\n",
       "[759140 rows x 8 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellinout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellinout.to_csv(r'C:\\Users\\the7490\\Downloads\\crs_sellin_out_bycurs_byweek.csv',encoding='gbk',index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_list = df1[['material','Net price']].drop_duplicates('material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_list_ka = va_ka[['Material','Net price']].drop_duplicates('Material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material</th>\n",
       "      <th>Net price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111210</th>\n",
       "      <td>113944</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111211</th>\n",
       "      <td>114264</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111212</th>\n",
       "      <td>114266</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37221</th>\n",
       "      <td>4078034</td>\n",
       "      <td>300.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37222</th>\n",
       "      <td>4078037</td>\n",
       "      <td>300.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112709</th>\n",
       "      <td>4069680</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180758</th>\n",
       "      <td>648731</td>\n",
       "      <td>135.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169678</th>\n",
       "      <td>4053374</td>\n",
       "      <td>331.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124216</th>\n",
       "      <td>4074512</td>\n",
       "      <td>181.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124243</th>\n",
       "      <td>4074509</td>\n",
       "      <td>110.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Material  Net price\n",
       "111210   113944       0.00\n",
       "111211   114264       0.00\n",
       "111212   114266       0.00\n",
       "37221   4078034     300.37\n",
       "37222   4078037     300.37\n",
       "...         ...        ...\n",
       "112709  4069680       0.00\n",
       "180758   648731     135.04\n",
       "169678  4053374     331.35\n",
       "124216  4074512     181.28\n",
       "124243  4074509     110.57\n",
       "\n",
       "[542 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sku_list_ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_list.to_csv(r'C:\\Users\\the7490\\Downloads\\sku_list.csv',encoding='gbk',index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 1： 备份\n",
    "    # normal/under ordering GAP = order - pgi - avail_inventory - transit\n",
    "    # over orderging and normal pgi type GAP = max boundary * avg_sales, sale_month - pgi - avail_inventory - transit\n",
    "gap_box_s1 = []\n",
    "ot,pt,stg,order,pgi,inv,mx,avg,trs = ['order_type','pgi_type','shortage','Order Qty','ConfirmQty','avail_inventory_box','MaxDays','avg_sales_box_day','intrans_inventory_box']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['shortage'][i] == 'shortage' and df['order_type'][i] != 'over': # normal and under\n",
    "        normal_under_gap = df[order][i] - df[pgi][i] - df[inv][i] - df[trs][i]\n",
    "        if normal_under_gap > 0: \n",
    "            gap_box_s1.append(normal_under_gap)\n",
    "        else:\n",
    "            gap_box_s1.append(None)\n",
    "    elif df[stg][i] == 'shortge' and df[ot][i] == 'over' and df[pt][i] =='normal':\n",
    "        over_gap = df[mx]*df[avg][i] - df[pgi][i] - df[inv][i] - df[trs][i]\n",
    "        if over_gap>0:\n",
    "            gap_box_s1.append(over_gap)\n",
    "        else:\n",
    "            gap_box_s1.append(None)\n",
    "    else:\n",
    "        gap_box_s1.append(None)\n",
    "#     elif df[stg][i] == 'shortge' and df[ot][i] == 'over' and df[pt][i] =='normal':\n",
    "#         over_gap = df[mx]*df[avg][i] - df[pgi][i] - df[inv][i] - df[trs][i]\n",
    "#         gap_box_s1.append(over_gap)\n",
    "#     else:\n",
    "#         gap_box_s1.append(0)\n",
    "\n",
    "df['gap_box_s1'] = gap_box_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 备份：按CusType横向展开\n",
    "\n",
    "# for all CusTypes join gap \n",
    "gap_df = pd.DataFrame(columns = ['year','week','material','Plnt','gap_box_s1','gap_box_s2','gap_box_s3','exceed_pgi_box'])\n",
    "\n",
    "for i in list(sku_gap['CusType'].unique()):\n",
    "    temp = sku_gap[sku_gap['CusType']==i]\n",
    "    temp = temp[~temp['material'].isna()].drop(columns =['CusType'])\n",
    "    #temp = temp.add_suffix('_'+i)\n",
    "    exec('df_%s=temp'%i)\n",
    "    gap_df = pd.merge(temp, gap_df, on=['year','week','material','Plnt'], how='outer',suffixes=('_'+i,''))\n",
    "\n",
    "#drop unwanted column\n",
    "gap_df = gap_df.drop(columns = ['gap_box_s1','gap_box_s2','gap_box_s3','exceed_pgi_box','exceed_pgi_box_KA']) # as KA do not have exceed pgi\n",
    "gap_df.rename(columns ={'exceed_pgi_box_CRS':'exceed'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag shortage_continuous_weeknum\n",
    "\n",
    "t = dfs[dfs['material']=='244090'][['year','week','material','num','Shortage_incl_61']].rename(columns = {'Shortage_incl_61':'stg'})\n",
    "t['row1'] = row_number(t, groupby_col=['material','stg'], orderby_col='num', ascending=True) # row_number over material and stg\n",
    "t['row2'] = t['num'].rank(ascending =True)\n",
    "t['row1'] = t[['row1','stg']].apply(lambda x: x['row1'] if x['stg'] ==1 else None, axis=1)\n",
    "t['diff'] = t['row2']-t['row1'] # same diff value means continuous stg\n",
    "    \n",
    "t1 = t.groupby(['material','diff']).agg({'row1':'count'}).reset_index().rename(columns={'row1':'count'}).sort_values('diff')\n",
    "t1['count_cum'] = t1['count'].cumsum(axis=0) # assit value to calculate continuous stg week starting from 1\n",
    "    \n",
    "dft = pd.merge(t,t1, on=['material','diff'],how='left')\n",
    "dft['stg_con'] = dft['row1'] - dft['count_cum'] + dft['count']\n",
    "    \n",
    "result_show(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original version - 连续周tag\n",
    "\n",
    "def row_number(df, groupby_col=[], orderby_col='', ascending=True):\n",
    "    return df.groupby(groupby_col)[orderby_col].rank(ascending=True)\n",
    "\n",
    "\n",
    "# Tag shortage weeknum \n",
    "tag_weeknum = []\n",
    "dfs = dfs[~dfs['material'].isna()]\n",
    "\n",
    "for sku in dfs['material'].unique():\n",
    "    t = dfs[dfs['material']==sku][['year','week','material','num','Shortage_incl_61']].rename(columns = {'Shortage_incl_61':'stg'})\n",
    "    t['row1'] = row_number(t, groupby_col=['material','stg'], orderby_col='num', ascending=True) # row_number over material and stg\n",
    "    t['row2'] = t['num'].rank(ascending =True)\n",
    "    t['row1'] = t[['row1','stg']].apply(lambda x: x['row1'] if x['stg'] ==1 else None, axis=1)\n",
    "    t['diff'] = t['row2']-t['row1'] # same diff value means continuous stg\n",
    "    \n",
    "    t1 = t.groupby(['material','diff']).agg({'row1':'count'}).reset_index().rename(columns={'row1':'count'}).sort_values('diff')\n",
    "    t1['count_cum'] = t1['count'].cumsum(axis=0) # assit value to calculate continuous stg week starting from 1\n",
    "    \n",
    "    dft = pd.merge(t,t1, on=['material','diff'],how='left')\n",
    "    dft['stg_con'] = dft['row1'] - dft['count_cum'] + dft['count']\n",
    "\n",
    "    tag_weeknum.append(dft)\n",
    "    \n",
    "sku_ct_stg = pd.concat(tag_weeknum)\n",
    "result_show(sku_ct_stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ka - ORIGINAL\n",
    "# Read ka data\n",
    "ka_cus = pd.read_csv(r'C:\\Users\\the7490\\Documents\\01 RDS\\data\\dim_customer_atom.csv',encoding='gbk')\n",
    "\n",
    "# Get list of ka sold_to_code\n",
    "ka = ka_cus[['sold_to_code','ka_type_bc']].astype(str)\n",
    "ka = ka[ka['ka_type_bc'].str.contains(r'NKA|LKA',regex=True)]\n",
    "ka_list =ka['sold_to_code'].astype(int)\n",
    "\n",
    "# Get ka SAP order data\n",
    "va_ka =va[va['Sold-To Pt'].isin(list(ka_list))]\n",
    "\n",
    "# keep records of ordered date only\n",
    "va_ka = va_ka[va_ka['Order Qty']>0]\n",
    "\n",
    "va_ka = trim(va_ka)\n",
    "va_ka[['Sold-To Pt','Material']] =va_ka[['Sold-To Pt','Material']].astype(int)\n",
    "\n",
    "# Gourp by Customer, Material, Date to map CRS data and count \n",
    "va_ka_grouped = va_ka[['Order Qty','ConfirmQty','Sold-To Pt','Material','Doc. Date','PO Number']].groupby([\"Sold-To Pt\",'Material','Doc. Date']).agg({'Order Qty':'sum','ConfirmQty':'sum','PO Number':'count'}).reset_index()\n",
    "va_ka_grouped.rename(columns ={'PO Number':'count'}, inplace = True)\n",
    "\n",
    "\n",
    "# Get Customer and SKU Info\n",
    "va_ka_cus = va_ka[[\"Sold-To Pt\",'Name 1','Plnt']].drop_duplicates(subset=['Sold-To Pt'],keep='first',inplace=False)\n",
    "va_ka_info = pd.merge(va_ka_grouped, va_ka_cus, on = 'Sold-To Pt',how = 'left')\n",
    "\n",
    "va_ka_sku = va_ka[[\"Material\",'Description','Net price']].drop_duplicates(subset=['Material'],keep='first',inplace=False)\n",
    "df_ka = pd.merge(va_ka_info, va_ka_sku, on = 'Material',how = 'left')\n",
    "\n",
    "# df_va =  pd.merge(df_va, date[['Date','year','week']], left_on = 'Doc. Date',right_on = 'Date',how = 'left') \n",
    "df_ka['year'] = df_ka['Doc. Date'].dt.year.astype(int)\n",
    "df_ka['week'] = df_ka['Doc. Date'].apply(lambda x: x.strftime(\"%W\")).astype(int)    # Start from Monday  \n",
    "df_ka['ds'] = df_ka['Doc. Date'].apply(lambda x: x.strftime(\"%Y%m%d\")).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAP处理考虑int\n",
    "# Filter out wanted columns and set data types\n",
    "va_df = va[['Rj','PO Number','Sold-To Pt','Name 1','Material','Description','Plnt','Order Qty','ConfirmQty','Doc. Date','Cust.price','Net price','SaTy']]\n",
    "va_df[['Sold-To Pt','Material']] = va_df[['Sold-To Pt','Material']].astype(str)\n",
    "va_df = va_df[~va_df['Material'].str.contains(r'DM')]\n",
    "va_df[['Material']] = va_df[['Material']].astype(float)\n",
    "\n",
    "# Remove na material rows\n",
    "va_df = va_df[~va_df['Material'].isna()]\n",
    "\n",
    "va_df[['Material','Sold-To Pt']] = va_df[['Material','Sold-To Pt']].astype(str)\n",
    "\n",
    "va_df[['Order Qty','ConfirmQty']] = va_df[['Order Qty','ConfirmQty']].fillna(0).astype(int)\n",
    "\n",
    "# Saty == ZOR  and PO number start with VZO for CRS customer\n",
    "va_df =  va_df[va_df['SaTy']=='ZOR']\n",
    "va_df = va_df[va_df['PO Number'].str.contains(r'VZO*')]\n",
    "\n",
    "# Replace null with 0 for Rj\n",
    "va_df['Rj'] = va_df['Rj'].fillna(0).astype(int)\n",
    "\n",
    "# trim\n",
    "# va_df = trim(va_df)\n",
    "\n",
    "# Remove 61 code\n",
    "va_df = va_df[va_df['Rj']!= 61]\n",
    "\n",
    "# Set Rj=10 if order_qty > confrimQty and Rj is null\n",
    "# va_df['Rj'] = va_df[['Order Qty','ConfirmQty','Rj']].apply(lambda x: 10 if x['Rj']== 0 and x['Order Qty']> x['ConfirmQty'] else x['Rj'], axis =1)\n",
    "\n",
    "# Gourp by Customer, Material, Date to map CRS data and count \n",
    "va_df_grouped = va_df[['Order Qty','ConfirmQty','Sold-To Pt','Material','Doc. Date','Rj']].groupby([\"Sold-To Pt\",'Material','Doc. Date']).agg({'Order Qty':'sum','ConfirmQty':'sum','Rj':'count'}).reset_index()\n",
    "va_df_grouped.rename(columns ={'Rj':'count'}, inplace = True)\n",
    "\n",
    "\n",
    "# Get Customer and SKU Info\n",
    "va_cus = va_df[[\"Sold-To Pt\",'Name 1','Plnt']].drop_duplicates(subset=['Sold-To Pt'],keep='first',inplace=False)\n",
    "va_df_grouped_cus = pd.merge(va_df_grouped, va_cus, on = 'Sold-To Pt',how = 'left')\n",
    "\n",
    "va_sku = va_df[[\"Material\",'Description','Net price']].drop_duplicates(subset=['Material'],keep='first',inplace=False)\n",
    "df_va = pd.merge(va_df_grouped_cus, va_sku, on = 'Material',how = 'left')\n",
    "\n",
    "# df_va =  pd.merge(df_va, date[['Date','year','week']], left_on = 'Doc. Date',right_on = 'Date',how = 'left') \n",
    "df_va['year'] = df_va['Doc. Date'].dt.year.astype(int)\n",
    "df_va['week'] = df_va['Doc. Date'].apply(lambda x: x.strftime(\"%W\")).astype(int) # Start from Monday\n",
    "df_va['ds'] = df_va['Doc. Date'].apply(lambda x: x.strftime(\"%Y%m%d\")).astype(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
